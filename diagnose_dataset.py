"""
æ•°æ®é›†è¯Šæ–­å·¥å…·ï¼šç»Ÿè®¡50å¼ å›¾çš„æ ‡æ³¨åˆ†å¸ƒ
è¾“å‡ºï¼šæ¯ä¸ªç±»åˆ«çš„å®ä¾‹æ•°ã€æ¯å¼ å›¾çš„å®ä¾‹æ•°ã€æ˜¯å¦å­˜åœ¨ç©ºå›¾
"""
import os
import json
import yaml
from pathlib import Path
from collections import Counter
import argparse


def load_yaml(cfg_path: str):
    with open(cfg_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def parse_unified_txt(txt_path: Path):
    """è§£æç»Ÿä¸€TXTï¼Œè¿”å›å®ä¾‹åˆ—è¡¨"""
    instances = []
    if not txt_path.exists():
        return instances
    with open(txt_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            parts = line.split()
            if len(parts) < 7:  # è‡³å°‘5ID + 1ä¸ªç‚¹(x,y)
                continue
            try:
                species, cell_org, shape, flagella, chloroplast = map(int, parts[:5])
            except ValueError:
                continue
            coords = []
            try:
                coords = list(map(float, parts[5:]))
            except ValueError:
                continue
            if len(coords) < 2 or len(coords) % 2 != 0:
                continue
            instances.append({
                'species': species,
                'cell_org': cell_org,
                'shape': shape,
                'flagella': flagella,
                'chloroplast': chloroplast,
                'num_points': len(coords) // 2
            })
    return instances


def diagnose_dataset(cfg_path: str, data_root: str):
    cfg = load_yaml(cfg_path)
    data_root_p = Path(data_root)

    stats = {
        'total_images': 0,
        'total_instances': 0,
        'species': Counter(),
        'cell_org': Counter(),
        'shape': Counter(),
        'flagella': Counter(),
        'chloroplast': Counter(),
        'instances_per_image': [],
        'empty_images': []
    }

    for split in ['train', 'val']:
        img_dir = data_root_p / 'images' / split
        lbl_dir = data_root_p / 'labels' / split
        if not img_dir.exists():
            continue

        for img_file in img_dir.iterdir():
            if img_file.suffix.lower() not in {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}:
                continue
            stats['total_images'] += 1
            txt_file = lbl_dir / f"{img_file.stem}.txt"

            if not txt_file.exists():
                stats['empty_images'].append(str(img_file))
                stats['instances_per_image'].append(0)
                continue

            instances = parse_unified_txt(txt_file)
            num_inst = len(instances)
            stats['total_instances'] += num_inst
            stats['instances_per_image'].append(num_inst)

            for inst in instances:
                stats['species'][inst['species']] += 1
                stats['cell_org'][inst['cell_org']] += 1
                stats['shape'][inst['shape']] += 1
                stats['flagella'][inst['flagella']] += 1
                stats['chloroplast'][inst['chloroplast']] += 1

    # è¾“å‡ºåˆ°æ§åˆ¶å°
    print("\n" + "=" * 60)
    print("ğŸ“Š æ•°æ®é›†è¯Šæ–­æŠ¥å‘Šï¼ˆ50å¼ å›¾ï¼‰")
    print("=" * 60)
    print(f"æ€»å›¾åƒæ•°: {stats['total_images']}")
    print(f"æ€»å®ä¾‹æ•°: {stats['total_instances']}")
    avg_inst = stats['total_instances'] / max(stats['total_images'], 1)
    print(f"å¹³å‡æ¯å¼ å›¾å®ä¾‹æ•°: {avg_inst:.1f}")
    print(f"ç©ºå›¾æ•°é‡: {len(stats['empty_images'])}")

    # è·å–ä¸­æ–‡åç§°æ˜ å°„ï¼ˆç¨³å¥å¤„ç†ï¼šé”®è½¬ä¸º intï¼‰
    raw_names_zh = cfg.get('classes', {}).get('names_zh', {})
    names_zh = {}
    for k, v in raw_names_zh.items():
        try:
            names_zh[int(k)] = str(v)
        except Exception:
            # è·³è¿‡æ— æ³•è§£æçš„é”®
            continue
    def name_of(gid: int) -> str:
        return names_zh.get(int(gid), f"unknown_{gid}")

    print("\nğŸ“Œ species åˆ†å¸ƒ:")
    for cls_id, count in stats['species'].most_common():
        name = name_of(cls_id)
        print(f"  {name:20s} (ID={cls_id:2d}): {count:3d} å®ä¾‹")

    print("\nğŸ“Œ cell_organization åˆ†å¸ƒ:")
    for cls_id, count in stats['cell_org'].most_common():
        name = name_of(cls_id)
        print(f"  {name:20s} (ID={cls_id:2d}): {count:3d} å®ä¾‹")

    # é¢å¤–ï¼šä¾æ® label_spaces çš„ to_local èšåˆ cell_org åˆ° 4 ç±»ï¼ˆè‹¥å­˜åœ¨é…ç½®ï¼‰
    cell_org_space = cfg.get('classes', {}).get('label_spaces', {}).get('cell_org', {})
    to_local = cell_org_space.get('to_local', None)
    to_global = cell_org_space.get('to_global', None)
    if isinstance(to_local, dict):
        local_counter = Counter()
        for gid, cnt in stats['cell_org'].items():
            try:
                lid = to_local.get(int(gid), None)
            except Exception:
                lid = None
            if lid is not None:
                local_counter[int(lid)] += cnt
        if local_counter:
            print("\nğŸ“ cell_organization èšåˆï¼ˆè®­ç»ƒæœ¬åœ°4ç±»ï¼‰:")
            # ä½¿ç”¨ to_global å°†æœ¬åœ°ç±»æ˜ å°„åˆ°å¯¹åº”çš„å…¨å±€IDï¼Œå†å–ä¸­æ–‡å
            for lid, cnt in local_counter.most_common():
                if isinstance(to_global, dict):
                    gid = to_global.get(int(lid), lid)
                else:
                    gid = lid
                name = name_of(gid)
                print(f"  {name:20s} (local={lid}): {cnt:3d} å®ä¾‹")

    print("\nğŸ“Œ shape åˆ†å¸ƒ:")
    for cls_id, count in stats['shape'].most_common(10):
        name = name_of(cls_id)
        print(f"  {name:20s} (ID={cls_id:2d}): {count:3d} å®ä¾‹")

    print("\nğŸ“Œ flagella åˆ†å¸ƒ:")
    for cls_id, count in stats['flagella'].most_common(10):
        name = name_of(cls_id)
        print(f"  {name:20s} (ID={cls_id:2d}): {count:3d} å®ä¾‹")

    print("\nğŸ“Œ chloroplast åˆ†å¸ƒ:")
    for cls_id, count in stats['chloroplast'].most_common(10):
        name = name_of(cls_id)
        print(f"  {name:20s} (ID={cls_id:2d}): {count:3d} å®ä¾‹")

    print("\nâš ï¸  å»ºè®®:")
    if stats['total_instances'] < 200:
        print("  - å®ä¾‹æ•°<200ï¼Œå»ºè®®å¼ºæ•°æ®å¢å¼ºï¼ˆmosaic/mixup/æ—‹è½¬/ç¿»è½¬ï¼‰")
    if len(stats['empty_images']) > 0:
        print(f"  - æœ‰ {len(stats['empty_images'])} å¼ ç©ºå›¾ï¼Œå»ºè®®æ£€æŸ¥æ ‡æ³¨")
    if stats['total_images'] < 100:
        print("  - å›¾åƒæ•°<100ï¼ŒStage2å¤šå¤´åˆ†ç±»å»ºè®®æš‚æ—¶åªè®­ç»ƒspecieså•å¤´")

    return stats


def main():
    parser = argparse.ArgumentParser(description='ç»Ÿä¸€æ•°æ®é›†è¯Šæ–­')
    parser.add_argument('--cfg', type=str, default='g:/yoloV13/ÂµSHM-YOLO/yolov13_transformer_unified_v2_1.yaml')
    parser.add_argument('--data_root', type=str, default='g:/yoloV13/ÂµSHM-YOLO/samples')
    parser.add_argument('--out_json', type=str, default='g:/yoloV13/ÂµSHM-YOLO/tools/reports/dataset_diagnosis.json')
    args = parser.parse_args()

    stats = diagnose_dataset(args.cfg, args.data_root)

    # ä¿å­˜JSON
    output = {
        'summary': {
            'total_images': stats['total_images'],
            'total_instances': stats['total_instances'],
            'empty_images': stats['empty_images']
        },
        'species': dict(stats['species']),
        'cell_org': dict(stats['cell_org']),
        'shape': dict(stats['shape']),
        'flagella': dict(stats['flagella']),
        'chloroplast': dict(stats['chloroplast'])
    }

    os.makedirs(os.path.dirname(args.out_json), exist_ok=True)
    with open(args.out_json, 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜: {args.out_json}")
    print("=" * 60 + "\n")


if __name__ == '__main__':
    main()