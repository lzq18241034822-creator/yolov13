# ğŸ¯ åŸºäº50å¼ å›¾çš„å®Œæ•´è½åœ°æ–¹æ¡ˆï¼ˆå«ä»£ç ï¼‰

## ä¸€ã€ç°çŠ¶è¯Šæ–­ä¸ç­–ç•¥

### âœ… ä½ çš„çŠ¶æ€
- æ•°æ®ï¼š50å¼ å›¾å·²æ ‡æ³¨ï¼ˆç»Ÿä¸€TXTæ ¼å¼ï¼‰
- ä»£ç ï¼šYOLOv13æºç å·²ä¸‹è½½ï¼ˆ`yolov13-main/`ï¼‰
- ç›®æ ‡ï¼šå…ˆè·‘é€šâ†’éªŒè¯æ•ˆæœâ†’å¢åŠ æ•°æ®â†’ä¸€é”®æå‡

### âš ï¸ 50å¼ å›¾çš„é™åˆ¶ä¸å¯¹ç­–

| é˜¶æ®µ | æ˜¯å¦å¯è¡Œ | ç­–ç•¥ |
|------|----------|------|
| **Stage1 åˆ†å‰²** | âœ… å¯ä»¥ | å¼ºæ•°æ®å¢å¼º+æ—©åœï¼ˆepochs=50ï¼‰ |
| **Stage2 äº”å¤´åˆ†ç±»** | âš ï¸ å›°éš¾ | **æš‚æ—¶ç®€åŒ–ä¸ºå•å¤´**ï¼ˆåªè®­speciesï¼‰ |
| **Stage3 æ¨ç†** | âœ… å¯ä»¥ | å¯è§†åŒ–éªŒè¯ |

**æ ¸å¿ƒç­–ç•¥ï¼šå…ˆè·‘é€š"åˆ†å‰²+å•å±æ€§åˆ†ç±»+æ¨ç†"çš„æœ€å°é—­ç¯**

---

## äºŒã€5æ­¥è½åœ°è®¡åˆ’ï¼ˆæ¯æ­¥éƒ½æœ‰ä»£ç ï¼‰

```
æ­¥éª¤1ï¼šæ•°æ®è¯Šæ–­ â†’ ç¡®è®¤50å¼ å›¾å¤Ÿä¸å¤Ÿç”¨
æ­¥éª¤2ï¼šYOLOv13æ¥å…¥ â†’ æŠŠä¸»å¹²æ¨¡å‹æ¥åˆ°ä½ çš„æ•°æ®ç®¡é“
æ­¥éª¤3ï¼šStage1è®­ç»ƒ â†’ åˆ†å‰²åŸºçº¿ï¼ˆ50 epochsï¼‰
æ­¥éª¤4ï¼šStage2ç®€åŒ– â†’ åªè®­specieså•å¤´
æ­¥éª¤5ï¼šä¸€é”®è„šæœ¬ â†’ å¢é‡è®­ç»ƒè‡ªåŠ¨åŒ–
```

---

## æ­¥éª¤1ï¼šæ•°æ®è¯Šæ–­ï¼ˆ10åˆ†é’Ÿï¼‰

### ğŸ“„ åˆ›å»ºæ–‡ä»¶ï¼š`ÂµSHM-YOLO/tools/diagnose_dataset.py`

```python
"""
æ•°æ®é›†è¯Šæ–­å·¥å…·ï¼šç»Ÿè®¡50å¼ å›¾çš„æ ‡æ³¨åˆ†å¸ƒ
è¾“å‡ºï¼šæ¯ä¸ªç±»åˆ«çš„å®ä¾‹æ•°ã€æ¯å¼ å›¾çš„å®ä¾‹æ•°ã€æ˜¯å¦å­˜åœ¨ç©ºå›¾
"""
import os
import yaml
from pathlib import Path
from collections import Counter
import json

def load_yaml(cfg_path):
    with open(cfg_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def parse_unified_txt(txt_path):
    """è§£æç»Ÿä¸€TXTï¼Œè¿”å›å®ä¾‹åˆ—è¡¨"""
    instances = []
    with open(txt_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            parts = line.split()
            if len(parts) < 7:  # è‡³å°‘5ID + 1ä¸ªç‚¹(x,y)
                continue
            species, cell_org, shape, flagella, chloroplast = map(int, parts[:5])
            coords = list(map(float, parts[5:]))
            if len(coords) < 2 or len(coords) % 2 != 0:
                continue
            instances.append({
                'species': species,
                'cell_org': cell_org,
                'shape': shape,
                'flagella': flagella,
                'chloroplast': chloroplast,
                'num_points': len(coords) // 2
            })
    return instances

def main():
    cfg = load_yaml('g:/yoloV13/ÂµSHM-YOLO/yolov13_transformer_unified_v2_1.yaml')
    data_root = Path('g:/yoloV13/ÂµSHM-YOLO/samples')
    
    stats = {
        'total_images': 0,
        'total_instances': 0,
        'species': Counter(),
        'cell_org': Counter(),
        'shape': Counter(),
        'flagella': Counter(),
        'chloroplast': Counter(),
        'instances_per_image': [],
        'empty_images': []
    }
    
    # éå†trainå’Œval
    for split in ['train', 'val']:
        img_dir = data_root / 'images' / split
        lbl_dir = data_root / 'labels' / split
        if not img_dir.exists():
            continue
        
        for img_file in img_dir.glob('*'):
            if img_file.suffix.lower() not in ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff']:
                continue
            
            stats['total_images'] += 1
            txt_file = lbl_dir / f"{img_file.stem}.txt"
            
            if not txt_file.exists():
                stats['empty_images'].append(str(img_file))
                stats['instances_per_image'].append(0)
                continue
            
            instances = parse_unified_txt(txt_file)
            num_inst = len(instances)
            stats['total_instances'] += num_inst
            stats['instances_per_image'].append(num_inst)
            
            for inst in instances:
                stats['species'][inst['species']] += 1
                stats['cell_org'][inst['cell_org']] += 1
                stats['shape'][inst['shape']] += 1
                stats['flagella'][inst['flagella']] += 1
                stats['chloroplast'][inst['chloroplast']] += 1
    
    # è¾“å‡ºæŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ“Š æ•°æ®é›†è¯Šæ–­æŠ¥å‘Šï¼ˆ50å¼ å›¾ï¼‰")
    print("="*60)
    print(f"æ€»å›¾åƒæ•°: {stats['total_images']}")
    print(f"æ€»å®ä¾‹æ•°: {stats['total_instances']}")
    print(f"å¹³å‡æ¯å¼ å›¾å®ä¾‹æ•°: {stats['total_instances']/max(stats['total_images'], 1):.1f}")
    print(f"ç©ºå›¾æ•°é‡: {len(stats['empty_images'])}")
    
    # è·å–ç±»åˆ«åç§°
    species_names = {v: k for k, v in cfg['classes']['label_spaces']['species'].items()}
    cellorg_names = {v: k for k, v in cfg['classes']['label_spaces']['cell_org'].items()}
    
    print("\nğŸ“Œ species åˆ†å¸ƒ:")
    for cls_id, count in stats['species'].most_common():
        name = species_names.get(cls_id, f"unknown_{cls_id}")
        print(f"  {name:20s} (ID={cls_id:2d}): {count:3d} å®ä¾‹")
    
    print("\nğŸ“Œ cell_organization åˆ†å¸ƒ:")
    for cls_id, count in stats['cell_org'].most_common():
        name = cellorg_names.get(cls_id, f"unknown_{cls_id}")
        print(f"  {name:20s} (ID={cls_id:2d}): {count:3d} å®ä¾‹")
    
    print("\nğŸ“Œ shape åˆ†å¸ƒ:")
    for cls_id, count in stats['shape'].most_common(10):
        print(f"  shape_{cls_id:2d}: {count:3d} å®ä¾‹")
    
    print("\nâš ï¸  å»ºè®®:")
    if stats['total_instances'] < 200:
        print("  - å®ä¾‹æ•°<200ï¼Œå»ºè®®å¼ºæ•°æ®å¢å¼ºï¼ˆmosaic/mixup/æ—‹è½¬/ç¿»è½¬ï¼‰")
    if len(stats['empty_images']) > 0:
        print(f"  - æœ‰ {len(stats['empty_images'])} å¼ ç©ºå›¾ï¼Œå»ºè®®æ£€æŸ¥æ ‡æ³¨")
    if stats['total_images'] < 100:
        print("  - å›¾åƒæ•°<100ï¼ŒStage2å¤šå¤´åˆ†ç±»å»ºè®®æš‚æ—¶åªè®­ç»ƒspecieså•å¤´")
    
    # ä¿å­˜JSON
    output = {
        'summary': {
            'total_images': stats['total_images'],
            'total_instances': stats['total_instances'],
            'empty_images': stats['empty_images']
        },
        'species': dict(stats['species']),
        'cell_org': dict(stats['cell_org']),
        'shape': dict(stats['shape']),
        'flagella': dict(stats['flagella']),
        'chloroplast': dict(stats['chloroplast'])
    }
    
    out_path = 'g:/yoloV13/ÂµSHM-YOLO/tools/reports/dataset_diagnosis.json'
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    with open(out_path, 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜: {out_path}")
    print("="*60 + "\n")

if __name__ == '__main__':
    main()
```

### è¿è¡Œè¯Šæ–­

```powershell
cd g:\yoloV13\ÂµSHM-YOLO
python tools\diagnose_dataset.py
```

**çœ‹è¾“å‡ºï¼š**
- å¦‚æœæ€»å®ä¾‹æ•° < 200 â†’ Stage2åªè®­species
- å¦‚æœæŸç±»å®ä¾‹æ•° < 10 â†’ è¯¥ç±»å¯èƒ½æ— æ³•è®­ç»ƒ

---

## æ­¥éª¤2ï¼šYOLOv13æ ¸å¿ƒæ¨¡å—æ¥å…¥ï¼ˆ30åˆ†é’Ÿï¼‰

### ğŸ“ ä» `yolov13-main` å¤åˆ¶éœ€è¦çš„æ–‡ä»¶

åœ¨ä½ çš„ `g:\yoloV13\yolov13-main\ultralytics\` é‡Œæ‰¾è¿™äº›æ–‡ä»¶ï¼Œå¤åˆ¶åˆ° `ÂµSHM-YOLO/models/yolov13/`

```powershell
# åˆ›å»ºç›®å½•
mkdir g:\yoloV13\ÂµSHM-YOLO\models\yolov13

# éœ€è¦å¤åˆ¶çš„æ–‡ä»¶ï¼ˆä» yolov13-main/ultralytics/nn/ æå–ï¼‰
# 1. block.py â†’ åŒ…å« C2f, SPPF, RepNCSPELAN4
# 2. conv.py â†’ åŒ…å« Conv, DWConv
# 3. head.py â†’ åŒ…å« Detect, Segment (v8-seg)
```

### ğŸ“„ åˆ›å»ºç®€åŒ–ç‰ˆYOLOv13åˆ†å‰²æ¨¡å‹ï¼š`ÂµSHM-YOLO/models/yolov13_seg_film.py`

```python
"""
YOLOv13åˆ†å‰²æ¨¡å‹ + FiLMæ³¨å…¥
åŸºäº iMoonLab/yolov13 çš„ Segment æ¶æ„
"""
import torch
import torch.nn as nn
from pathlib import Path
import sys

# åŠ¨æ€å¯¼å…¥yolov13-mainçš„æ¨¡å—
YOLOV13_PATH = Path('g:/yoloV13/yolov13-main')
if str(YOLOV13_PATH) not in sys.path:
    sys.path.insert(0, str(YOLOV13_PATH))

try:
    # å°è¯•å¯¼å…¥YOLOv13çš„æ ¸å¿ƒæ¨¡å—
    from ultralytics.nn.modules.conv import Conv
    from ultralytics.nn.modules.block import C2f, SPPF
    from ultralytics.nn.modules.head import Segment
    YOLOV13_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  æ— æ³•å¯¼å…¥YOLOv13æ¨¡å—: {e}")
    print(f"   è¯·ç¡®è®¤ {YOLOV13_PATH} å­˜åœ¨ä¸”åŒ…å« ultralytics/nn/")
    YOLOV13_AVAILABLE = False
    # é™çº§åˆ°ç®€æ˜“ç‰ˆ
    Conv = None
    C2f = None
    SPPF = None
    Segment = None

# å¯¼å…¥è‡ªå·±çš„FiLMæ¨¡å—
sys.path.insert(0, 'g:/yoloV13/ÂµSHM-YOLO')
from models.uscale_film import PixelScaleNormalizer, FiLM2d


class YOLOv13SegFiLM(nn.Module):
    """
    YOLOv13åˆ†å‰² + FiLMåƒç´ å°ºåº¦æ³¨å…¥
    
    æ¶æ„ï¼š
    - Backbone: YOLOv13-n (nano) with FiLM at S3/S4
    - Neck: simplified FPN/PAN
    - Head: Segment (proto + coefficients)
    """
    def __init__(self, num_classes=1, imgsz=640, pixel_size_um_default=0.0863):
        super().__init__()
        self.num_classes = num_classes
        self.imgsz = imgsz
        
        # åƒç´ å°ºåº¦å½’ä¸€åŒ–å™¨
        self.scale_norm = PixelScaleNormalizer(default_pixel_size=pixel_size_um_default)
        
        if not YOLOV13_AVAILABLE:
            print("âš ï¸  YOLOv13æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€æ˜“ç‰ˆåˆ†å‰²ç½‘ç»œ")
            from models.simple_seg_film import SimpleSegNetFiLM
            self.model = SimpleSegNetFiLM(num_classes=num_classes)
            self.is_fallback = True
            return
        
        self.is_fallback = False
        
        # ========== Backbone (YOLOv13-nano simplified) ==========
        # Stem
        self.stem = Conv(3, 16, k=3, s=2)  # 640 â†’ 320, c=16
        
        # Stage 1 (P1)
        self.stage1 = nn.Sequential(
            Conv(16, 32, k=3, s=2),  # 320 â†’ 160, c=32
            C2f(32, 32, n=1)
        )
        
        # Stage 2 (P2) - ç”¨äºå°ç›®æ ‡
        self.stage2 = nn.Sequential(
            Conv(32, 64, k=3, s=2),  # 160 â†’ 80, c=64
            C2f(64, 64, n=2)
        )
        self.film_p2 = FiLM2d(64)  # FiLMæ³¨å…¥
        
        # Stage 3 (P3)
        self.stage3 = nn.Sequential(
            Conv(64, 128, k=3, s=2),  # 80 â†’ 40, c=128
            C2f(128, 128, n=2)
        )
        self.film_p3 = FiLM2d(128)  # FiLMæ³¨å…¥
        
        # Stage 4 (P4)
        self.stage4 = nn.Sequential(
            Conv(128, 256, k=3, s=2),  # 40 â†’ 20, c=256
            C2f(256, 256, n=1),
            SPPF(256, 256, k=5)
        )
        self.film_p4 = FiLM2d(256)  # FiLMæ³¨å…¥
        
        # ========== Neck (ç®€åŒ–ç‰ˆPAN) ==========
        # Top-down
        self.up1 = nn.Upsample(scale_factor=2, mode='nearest')
        self.c3_p3 = C2f(256 + 128, 128, n=1)
        
        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')
        self.c3_p2 = C2f(128 + 64, 64, n=1)
        
        # Bottom-up
        self.down1 = Conv(64, 64, k=3, s=2)
        self.c3_n3 = C2f(64 + 128, 128, n=1)
        
        self.down2 = Conv(128, 128, k=3, s=2)
        self.c3_n4 = C2f(128 + 256, 256, n=1)
        
        # ========== Segmentation Head ==========
        # Proto mask (åœ¨P2å±‚ç”Ÿæˆ32ä¸ªåŸå‹mask)
        self.proto = nn.Sequential(
            Conv(64, 64, k=3),
            nn.Upsample(scale_factor=2, mode='nearest'),  # 80 â†’ 160
            Conv(64, 32, k=3),
            nn.Upsample(scale_factor=2, mode='nearest'),  # 160 â†’ 320
            Conv(32, 32, k=3)  # è¾“å‡º32ä¸ªåŸå‹ (320x320)
        )
        
        # Coefficient head (åœ¨P2/P3/P4è¾“å‡º32ç»´ç³»æ•°)
        self.coeff_p2 = nn.Conv2d(64, 32, 1)   # æ¯ä¸ªanchoré¢„æµ‹32ç»´ç³»æ•°
        self.coeff_p3 = nn.Conv2d(128, 32, 1)
        self.coeff_p4 = nn.Conv2d(256, 32, 1)
        
        # åˆ†ç±»å¤´ï¼ˆå•ç±»åˆ†å‰²ï¼‰
        self.cls_p2 = nn.Conv2d(64, num_classes, 1)
        self.cls_p3 = nn.Conv2d(128, num_classes, 1)
        self.cls_p4 = nn.Conv2d(256, num_classes, 1)
    
    def forward(self, x, pixel_size_um=None):
        """
        Args:
            x: (B, 3, H, W)
            pixel_size_um: (B,) æˆ– None
        Returns:
            dict: {
                'proto': (B, 32, H/2, W/2),  # åŸå‹masks
                'coeffs': [(B, 32, H_p2, W_p2), ...],  # P2/P3/P4çš„ç³»æ•°
                'cls': [(B, C, H_p2, W_p2), ...],  # åˆ†ç±»logits
            }
        """
        if self.is_fallback:
            # é™çº§åˆ°ç®€æ˜“ç½‘ç»œ
            out = self.model(x, pixel_size_um)
            # è½¬æ¢æ ¼å¼ä»¥å…¼å®¹è®­ç»ƒè„šæœ¬
            return {
                'mask': out,  # (B, 1, H, W)
                'proto': None,
                'coeffs': [],
                'cls': []
            }
        
        # å½’ä¸€åŒ–pixel_scale
        if pixel_size_um is None:
            pixel_size_um = torch.full((x.size(0),), self.scale_norm.default_pixel_size, device=x.device)
        scale_cond = self.scale_norm(pixel_size_um)  # (B, 1)
        
        # Backbone
        x = self.stem(x)
        p1 = self.stage1(x)
        p2 = self.stage2(p1)
        p2 = self.film_p2(p2, scale_cond)  # FiLMè°ƒåˆ¶
        
        p3 = self.stage3(p2)
        p3 = self.film_p3(p3, scale_cond)
        
        p4 = self.stage4(p3)
        p4 = self.film_p4(p4, scale_cond)
        
        # Neck (PAN)
        # Top-down
        x_up = self.up1(p4)
        x_up = torch.cat([x_up, p3], dim=1)
        n3 = self.c3_p3(x_up)
        
        x_up = self.up2(n3)
        x_up = torch.cat([x_up, p2], dim=1)
        n2 = self.c3_p2(x_up)  # (B, 64, 80, 80)
        
        # Bottom-up
        x_down = self.down1(n2)
        x_down = torch.cat([x_down, n3], dim=1)
        n3_out = self.c3_n3(x_down)  # (B, 128, 40, 40)
        
        x_down = self.down2(n3_out)
        x_down = torch.cat([x_down, p4], dim=1)
        n4_out = self.c3_n4(x_down)  # (B, 256, 20, 20)
        
        # Segmentation Head
        proto = self.proto(n2)  # (B, 32, 320, 320)
        
        coeff_p2 = self.coeff_p2(n2)  # (B, 32, 80, 80)
        coeff_p3 = self.coeff_p3(n3_out)  # (B, 32, 40, 40)
        coeff_p4 = self.coeff_p4(n4_out)  # (B, 32, 20, 20)
        
        cls_p2 = self.cls_p2(n2)
        cls_p3 = self.cls_p3(n3_out)
        cls_p4 = self.cls_p4(n4_out)
        
        return {
            'proto': proto,
            'coeffs': [coeff_p2, coeff_p3, coeff_p4],
            'cls': [cls_p2, cls_p3, cls_p4]
        }


if __name__ == '__main__':
    # æµ‹è¯•
    model = YOLOv13SegFiLM(num_classes=1, imgsz=640)
    x = torch.randn(2, 3, 640, 640)
    pixel_size = torch.tensor([0.0863, 0.1])
    
    out = model(x, pixel_size)
    
    if not model.is_fallback:
        print(f"âœ… YOLOv13-Seg-FiLM æµ‹è¯•é€šè¿‡")
        print(f"   proto: {out['proto'].shape}")
        print(f"   coeffs: {[c.shape for c in out['coeffs']]}")
        print(f"   cls: {[c.shape for c in out['cls']]}")
    else:
        print(f"âœ… é™çº§æ¨¡å¼æµ‹è¯•é€šè¿‡")
        print(f"   mask: {out['mask'].shape}")
```

### æµ‹è¯•YOLOv13æ¥å…¥

```powershell
cd g:\yoloV13\ÂµSHM-YOLO
python models\yolov13_seg_film.py
```

**é¢„æœŸè¾“å‡ºï¼š**
```
âœ… YOLOv13-Seg-FiLM æµ‹è¯•é€šè¿‡
   proto: torch.Size([2, 32, 320, 320])
   coeffs: [torch.Size([2, 32, 80, 80]), ...]
   cls: [torch.Size([2, 1, 80, 80]), ...]
```

å¦‚æœæŠ¥é”™"æ— æ³•å¯¼å…¥"â†’ ä¼šè‡ªåŠ¨é™çº§åˆ° `SimpleSegNetFiLM`

---

## æ­¥éª¤3ï¼šStage1è®­ç»ƒè„šæœ¬ï¼ˆé€‚é…YOLOv13ï¼‰

### ğŸ“„ åˆ›å»ºæ–‡ä»¶ï¼š`ÂµSHM-YOLO/tools/train_stage1_yolov13_film.py`

```python
"""
Stage1è®­ç»ƒï¼šYOLOv13åˆ†å‰² + FiLMæ³¨å…¥
é€‚é…50å¼ å›¾çš„å°æ•°æ®é›†ç­–ç•¥
"""
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import yaml
import argparse
from pathlib import Path
import os
import sys

sys.path.insert(0, 'g:/yoloV13/ÂµSHM-YOLO')

from datasets.unified_seg_dataset import UnifiedSegDataset, collate_fn_unified
from models.yolov13_seg_film import YOLOv13SegFiLM
from utils.losses_seg import BCEDiceLoss
from utils.early_stop import EarlyStopping
from utils.mask_ops import segments_to_masks_batch
import cv2
import numpy as np


def compute_mask_loss(pred_proto, pred_coeffs, pred_cls, gt_masks, gt_labels):
    """
    è®¡ç®—YOLOv13åˆ†å‰²æŸå¤±ï¼ˆç®€åŒ–ç‰ˆï¼‰
    Args:
        pred_proto: (B, 32, H, W)
        pred_coeffs: list of (B, 32, H_i, W_i)
        pred_cls: list of (B, C, H_i, W_i)
        gt_masks: (B, N_max, H, W)
        gt_labels: (B, N_max)  # 1=å‰æ™¯, 0=padding
    """
    device = pred_proto.device
    B, num_proto, H_proto, W_proto = pred_proto.shape
    
    # ç®€åŒ–ï¼šåªç”¨P2å±‚çš„ç³»æ•°ï¼ˆ80x80ï¼‰
    coeff = pred_coeffs[0]  # (B, 32, 80, 80)
    cls_out = pred_cls[0]   # (B, C, 80, 80)
    
    # ä¸‹é‡‡æ ·GT masksåˆ°80x80
    gt_masks_small = torch.nn.functional.interpolate(
        gt_masks.float(), size=(80, 80), mode='nearest'
    )  # (B, N_max, 80, 80)
    
    loss_bce_dice = BCEDiceLoss()
    total_loss = 0.0
    num_valid = 0
    
    for b in range(B):
        valid_mask = gt_labels[b] > 0  # (N_max,)
        if not valid_mask.any():
            continue
        
        num_inst = valid_mask.sum().item()
        
        # å–è¯¥batchçš„æ‰€æœ‰å‰æ™¯å®ä¾‹
        gt_b = gt_masks_small[b, valid_mask]  # (N_inst, 80, 80)
        
        # ç®€åŒ–ï¼šå–coeffçš„å‡å€¼ä½œä¸ºæ¯ä¸ªå®ä¾‹çš„ç³»æ•°ï¼ˆå®é™…åº”ç”¨éœ€anchoråŒ¹é…ï¼‰
        # è¿™é‡Œä¸ºäº†è·‘é€šæµç¨‹ï¼Œéšæœºé‡‡æ ·ç³»æ•°
        H_c, W_c = coeff.shape[2], coeff.shape[3]
        indices = torch.randint(0, H_c*W_c, (num_inst,), device=device)
        coeff_flat = coeff[b].view(32, -1)  # (32, H*W)
        inst_coeff = coeff_flat[:, indices].T  # (N_inst, 32)
        
        # ä¸protoç›¸ä¹˜å¾—åˆ°é¢„æµ‹masks
        proto_b = pred_proto[b]  # (32, H_proto, W_proto)
        pred_masks = torch.einsum('nc,chw->nhw', inst_coeff, proto_b)  # (N_inst, H, W)
        pred_masks = torch.sigmoid(pred_masks)
        
        # ä¸‹é‡‡æ ·åˆ°80x80
        pred_masks = torch.nn.functional.interpolate(
            pred_masks.unsqueeze(0), size=(80, 80), mode='bilinear', align_corners=False
        ).squeeze(0)  # (N_inst, 80, 80)
        
        # è®¡ç®—æŸå¤±
        loss = loss_bce_dice(pred_masks, gt_b)
        total_loss += loss
        num_valid += 1
    
    if num_valid == 0:
        return torch.tensor(0.0, device=device)
    
    return total_loss / num_valid


def train_one_epoch(model, loader, optimizer, device, epoch):
    model.train()
    total_loss = 0.0
    
    for i, batch in enumerate(loader):
        imgs = batch['images'].to(device)  # (B, 3, H, W)
        segments = batch['segments']  # list of (N_i, 2)
        labels = batch['labels']  # list of (N_i, 5)
        pixel_size_um = batch.get('pixel_size_um', None)
        
        if pixel_size_um is not None:
            pixel_size_um = pixel_size_um.to(device)
        
        # ç”ŸæˆGT masks
        B, _, H, W = imgs.shape
        gt_masks, gt_labels_mask = segments_to_masks_batch(
            segments, labels, H, W, device, max_instances=16
        )  # (B, 16, H, W), (B, 16)
        
        # å‰å‘
        out = model(imgs, pixel_size_um)
        
        # åˆ¤æ–­æ˜¯é™çº§æ¨¡å¼è¿˜æ˜¯YOLOv13æ¨¡å¼
        if 'mask' in out and out['proto'] is None:
            # é™çº§æ¨¡å¼ï¼ˆSimpleSegNetFiLMï¼‰
            pred_mask = out['mask']  # (B, 1, H, W)
            # ç®€åŒ–æŸå¤±ï¼šæ‰€æœ‰GT masksåˆå¹¶
            gt_merged = (gt_masks.sum(dim=1, keepdim=True) > 0).float()  # (B, 1, H, W)
            loss_fn = BCEDiceLoss()
            loss = loss_fn(torch.sigmoid(pred_mask), gt_merged)
        else:
            # YOLOv13æ¨¡å¼
            loss = compute_mask_loss(
                out['proto'], out['coeffs'], out['cls'],
                gt_masks, gt_labels_mask
            )
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        
        if (i + 1) % 5 == 0:
            print(f"  Batch [{i+1}/{len(loader)}] Loss: {loss.item():.4f}")
    
    return total_loss / len(loader)


def validate(model, loader, device):
    model.eval()
    total_loss = 0.0
    
    with torch.no_grad():
        for batch in loader:
            imgs = batch['images'].to(device)
            segments = batch['segments']
            labels = batch['labels']
            pixel_size_um = batch.get('pixel_size_um', None)
            
            if pixel_size_um is not None:
                pixel_size_um = pixel_size_um.to(device)
            
            B, _, H, W = imgs.shape
            gt_masks, gt_labels_mask = segments_to_masks_batch(
                segments, labels, H, W, device, max_instances=16
            )
            
            out = model(imgs, pixel_size_um)
            
            if 'mask' in out and out['proto'] is None:
                pred_mask = out['mask']
                gt_merged = (gt_masks.sum(dim=1, keepdim=True) > 0).float()
                loss_fn = BCEDiceLoss()
                loss = loss_fn(torch.sigmoid(pred_mask), gt_merged)
            else:
                loss = compute_mask_loss(
                    out['proto'], out['coeffs'], out['cls'],
                    gt_masks, gt_labels_mask
                )
            
            total_loss += loss.item()
    
    return total_loss / len(loader)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--cfg', default='g:/yoloV13/ÂµSHM-YOLO/yolov13_transformer_unified_v2_1.yaml')
    parser.add_argument('--data_root', default='g:/yoloV13/ÂµSHM-YOLO/samples')
    parser.add_argument('--split_dir', default='g:/yoloV13/ÂµSHM-YOLO/splits')
    parser.add_argument('--epochs', type=int, default=50)
    parser.add_argument('--batch_size', type=int, default=4)
    parser.add_argument('--imgsz', type=int, default=640)
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--device', default='cuda' if torch.cuda.is_available() else 'cpu')
    parser.add_argument('--workers', type=int, default=0)
    parser.add_argument('--save_dir', default='g:/yoloV13/runs/stage1_yolov13_film')
    args = parser.parse_args()
    
    os.makedirs(args.save_dir, exist_ok=True)
    
    # åŠ è½½é…ç½®
    with open(args.cfg, 'r', encoding='utf-8') as f:
        cfg = yaml.safe_load(f)
    
    # æ•°æ®é›†ï¼ˆå¼ºå¢å¼ºç­–ç•¥ï¼‰
    train_ds = UnifiedSegDataset(
        data_root=args.data_root,
        cfg=cfg,
        split='train',
        imgsz=args.imgsz,
        augment=True,  # å¼ºå¢å¼º
        mosaic=0.5,    # 50%æ¦‚ç‡mosaic
        split_list_path=Path(args.split_dir) / 'train.txt'
    )
    
    val_ds = UnifiedSegDataset(
        data_root=args.data_root,
        cfg=cfg,
        split='val',
        imgsz=args.imgsz,
        augment=False,
        split_list_path=Path(args.split_dir) / 'val.txt'
    )
    
    train_loader = DataLoader(
        train_ds, batch_size=args.batch_size, shuffle=True,
        num_workers=args.workers, collate_fn=collate_fn_unified, pin_memory=True
    )
    
    val_loader = DataLoader(
        val_ds, batch_size=args.batch_size, shuffle=False,
        num_workers=args.workers, collate_fn=collate_fn_unified
    )
    
    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ: train={len(train_ds)}, val={len(val_ds)}")
    
    # æ¨¡å‹
    pixel_size_default = cfg['microscope']['pixel_size_um']
    model = YOLOv13SegFiLM(num_classes=1, imgsz=args.imgsz, pixel_size_um_default=pixel_size_default)
    model = model.to(args.device)
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.Adam(model.parameters(), lr=args.lr)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)
    early_stop = EarlyStopping(patience=15, min_delta=0.001)
    
    best_loss = float('inf')
    
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ (è®¾å¤‡={args.device}, epochs={args.epochs})")
    print("="*60)
    
    for epoch in range(args.epochs):
        print(f"\nEpoch [{epoch+1}/{args.epochs}]")
        
        train_loss = train_one_epoch(model, train_loader, optimizer, args.device, epoch)
        val_loss = validate(model, val_loader, args.device)
        
        print(f"  Train Loss: {train_loss:.4f}")
        print(f"  Val Loss: {val_loss:.4f}")
        
        scheduler.step()
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_loss:
            best_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_loss,
            }, os.path.join(args.save_dir, 'best.pt'))
            print(f"  âœ… ä¿å­˜best.pt (val_loss={val_loss:.4f})")
        
        # æ—©åœ
        if early_stop(val_loss):
            print(f"\nâš ï¸  æ—©åœè§¦å‘ (epoch={epoch+1})")
            break
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼æœ€ä½³val_loss={best_loss:.4f}")
    print(f"   æƒé‡ä¿å­˜åœ¨: {args.save_dir}/best.pt")


if __name__ == '__main__':
    main()
```

### è¿è¡ŒStage1è®­ç»ƒ

```powershell
# å…ˆç”Ÿæˆtrain/valåˆ’åˆ†ï¼ˆ40å¼ trainï¼Œ10å¼ valï¼‰
python g:\yoloV13\ÂµSHM-YOLO\tools\make_fixed_split.py --data_root g:\yoloV13\ÂµSHM-YOLO\samples --val_ratio 0.2 --out_dir g:\yoloV13\ÂµSHM-YOLO\splits

# å¼€å§‹è®­ç»ƒï¼ˆCPUç‰ˆæœ¬ï¼Œå¦‚æœæœ‰GPUæŠŠ--deviceæ”¹ä¸ºcudaï¼‰
python g:\yoloV13\ÂµSHM-YOLO\tools\train_stage1_yolov13_film.py --epochs 50 --batch_size 4 --imgsz 640 --device cpu --workers 0 --save_dir g:\yoloV13\runs\stage1_film_50imgs
```

**é¢„æœŸè¾“å‡ºï¼š**
```
âœ… æ•°æ®é›†åŠ è½½å®Œæˆ: train=40, val=10
ğŸš€ å¼€å§‹è®­ç»ƒ (è®¾å¤‡=cpu, epochs=50)
Epoch [1/50]
  Batch [5/10] Loss: 0.6234
  Train Loss: 0.5891
  Val Loss: 0.5123
  âœ… ä¿å­˜best.pt (val_loss=0.5123)
...
```

---

## æ­¥éª¤4ï¼šStage2ç®€åŒ–ç‰ˆï¼ˆåªè®­specieså•å¤´ï¼‰

### ğŸ“„ åˆ›å»ºæ–‡ä»¶ï¼š`ÂµSHM-YOLO/tools/train_stage2_species_only.py`

```python
"""
Stage2ç®€åŒ–ç‰ˆï¼šåªè®­ç»ƒspecieså•å¤´
é€‚ç”¨äº50å¼ å›¾çš„å°æ•°æ®é›†
"""
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import yaml
import argparse
import os
import sys
from pathlib import Path

sys.path.insert(0, 'g:/yoloV13/ÂµSHM-YOLO')

from datasets.roi_multitask_dataset import ROIMultitaskDataset
from utils.early_stop import EarlyStopping
from torchvision.models import resnet18


class SpeciesClassifier(nn.Module):
    """å•å¤´speciesåˆ†ç±»å™¨ï¼ˆResNet18ï¼‰"""
    def __init__(self, num_species=45):
        super().__init__()
        self.backbone = resnet18(pretrained=True)
        # æ›¿æ¢æœ€åä¸€å±‚
        in_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Linear(in_features, num_species)
    
    def forward(self, x):
        return self.backbone(x)


def train_epoch(model, loader, optimizer, criterion, device):
    model.train()
    total_loss = 0.0
    correct = 0
    total = 0
    
    for batch in loader:
        imgs = batch['image'].to(device)
        species = batch['species'].to(device)
        
        logits = model(imgs)
        loss = criterion(logits, species)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        
        pred = logits.argmax(dim=1)
        correct += (pred == species).sum().item()
        total += species.size(0)
    
    acc = correct / max(total, 1)
    return total_loss / len(loader), acc


def validate(model, loader, criterion, device):
    model.eval()
    total_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for batch in loader:
            imgs = batch['image'].to(device)
            species = batch['species'].to(device)
            
            logits = model(imgs)
            loss = criterion(logits, species)
            
            total_loss += loss.item()
            
            pred = logits.argmax(dim=1)
            correct += (pred == species).sum().item()
            total += species.size(0)
    
    acc = correct / max(total, 1)
    return total_loss / len(loader), acc


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--cfg', default='g:/yoloV13/ÂµSHM-YOLO/yolov13_transformer_unified_v2_1.yaml')
    parser.add_argument('--roi_root', default='g:/yoloV13/ÂµSHM-YOLO/tools/reports')
    parser.add_argument('--epochs', type=int, default=30)
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--device', default='cuda' if torch.cuda.is_available() else 'cpu')
    parser.add_argument('--save_dir', default='g:/yoloV13/runs/stage2_species')
    args = parser.parse_args()
    
    os.makedirs(args.save_dir, exist_ok=True)
    
    with open(args.cfg, 'r', encoding='utf-8') as f:
        cfg = yaml.safe_load(f)
    
    # æ•°æ®é›†
    train_ds = ROIMultitaskDataset(
        roi_root=args.roi_root,
        cfg=cfg,
        split='train',
        augment=True
    )
    
    val_ds = ROIMultitaskDataset(
        roi_root=args.roi_root,
        cfg=cfg,
        split='val',
        augment=False
    )
    
    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=0)
    
    print(f"âœ… ROIæ•°æ®é›†: train={len(train_ds)}, val={len(val_ds)}")
    
    # æ¨¡å‹
    num_species = len(cfg['classes']['label_spaces']['species'])
    model = SpeciesClassifier(num_species=num_species).to(args.device)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=args.lr)
    early_stop = EarlyStopping(patience=10)
    
    best_acc = 0.0
    
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒspeciesåˆ†ç±»å™¨ (epochs={args.epochs})")
    print("="*60)
    
    for epoch in range(args.epochs):
        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, args.device)
        val_loss, val_acc = validate(model, val_loader, criterion, args.device)
        
        print(f"Epoch [{epoch+1}/{args.epochs}] Train Loss={train_loss:.4f} Acc={train_acc:.3f} | Val Loss={val_loss:.4f} Acc={val_acc:.3f}")
        
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), os.path.join(args.save_dir, 'best_species.pt'))
            print(f"  âœ… ä¿å­˜best_species.pt (acc={val_acc:.3f})")
        
        if early_stop(val_loss):
            print(f"âš ï¸  æ—©åœè§¦å‘")
            break
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼æœ€ä½³acc={best_acc:.3f}")


if __name__ == '__main__':
    main()
```

**å…ˆå¯¼å‡ºROIï¼ˆä»Stage1ï¼‰ï¼š**

```powershell
# ä¿®æ”¹ tools/train_stage1_yolov13_film.pyï¼Œåœ¨è®­ç»ƒç»“æŸååŠ å…¥å¯¼å‡ºROIçš„ä»£ç 
# æˆ–å•ç‹¬è¿è¡Œå¯¼å‡ºè„šæœ¬ï¼ˆéœ€è¦å…ˆå®ç°ï¼Œè¿™é‡Œæš‚æ—¶è·³è¿‡ï¼‰
```

**è¿è¡ŒStage2ï¼š**

```powershell
python g:\yoloV13\ÂµSHM-YOLO\tools\train_stage2_species_only.py --epochs 30 --batch_size 16 --device cpu --save_dir g:\yoloV13\runs\stage2_species_50imgs
```

---

## æ­¥éª¤5ï¼šä¸€é”®å¢é‡è®­ç»ƒè„šæœ¬

### ğŸ“„ åˆ›å»ºæ–‡ä»¶ï¼š`ÂµSHM-YOLO/train_incremental.py`

```python
"""
ä¸€é”®å¢é‡è®­ç»ƒè„šæœ¬
åŠŸèƒ½ï¼š
1. æ£€æµ‹æ–°å¢å›¾ç‰‡
2. è‡ªåŠ¨ç”Ÿæˆæ–°çš„train/valåˆ’åˆ†
3. å¢é‡è®­ç»ƒStage1å’ŒStage2
4. è¯„ä¼°æ•ˆæœå¹¶ç”ŸæˆæŠ¥å‘Š
"""
import os
import subprocess
import json
from pathlib import Path
import shutil

def run_cmd(cmd):
    """è¿è¡Œå‘½ä»¤å¹¶å®æ—¶è¾“å‡º"""
    print(f"\nğŸ”¹ è¿è¡Œå‘½ä»¤: {cmd}")
    result = subprocess.run(cmd, shell=True, capture_output=False, text=True)
    if result.returncode != 0:
        print(f"âŒ å‘½ä»¤å¤±è´¥: {cmd}")
        return False
    return True

def main():
    print("="*70)
    print("ğŸš€ ÂµSHM-YOLO ä¸€é”®å¢é‡è®­ç»ƒ")
    print("="*70)
    
    # é…ç½®è·¯å¾„
    data_root = Path('g:/yoloV13/ÂµSHM-YOLO/samples')
    split_dir = Path('g:/yoloV13/ÂµSHM-YOLO/splits')
    cfg_path = 'g:/yoloV13/ÂµSHM-YOLO/yolov13_transformer_unified_v2_1.yaml'
    
    # æ­¥éª¤1ï¼šæ•°æ®è¯Šæ–­
    print("\nğŸ“Š æ­¥éª¤1ï¼šæ•°æ®è¯Šæ–­")
    if not run_cmd('python g:/yoloV13/ÂµSHM-YOLO/tools/diagnose_dataset.py'):
        return
    
    # æ£€æŸ¥è¯Šæ–­ç»“æœ
    diag_file = 'g:/yoloV13/ÂµSHM-YOLO/tools/reports/dataset_diagnosis.json'
    if Path(diag_file).exists():
        with open(diag_file, 'r') as f:
            diag = json.load(f)
        total_imgs = diag['summary']['total_images']
        total_insts = diag['summary']['total_instances']
        print(f"   ğŸ“Œ æ€»å›¾åƒ: {total_imgs}, æ€»å®ä¾‹: {total_insts}")
        
        if total_imgs < 100:
            print("   âš ï¸  å›¾åƒæ•°<100ï¼ŒStage2å°†ä½¿ç”¨ç®€åŒ–æ¨¡å¼")
    
    # æ­¥éª¤2ï¼šç”Ÿæˆåˆ’åˆ†
    print("\nğŸ“‚ æ­¥éª¤2ï¼šç”Ÿæˆtrain/valåˆ’åˆ†")
    if not run_cmd(f'python g:/yoloV13/ÂµSHM-YOLO/tools/make_fixed_split.py --data_root {data_root} --val_ratio 0.2 --out_dir {split_dir}'):
        return
    
    # æ­¥éª¤3ï¼šStage1è®­ç»ƒ
    print("\nğŸ”§ æ­¥éª¤3ï¼šStage1åˆ†å‰²è®­ç»ƒ")
    stage1_cmd = (
        f'python g:/yoloV13/ÂµSHM-YOLO/tools/train_stage1_yolov13_film.py '
        f'--cfg {cfg_path} '
        f'--data_root {data_root} '
        f'--split_dir {split_dir} '
        f'--epochs 50 '
        f'--batch_size 4 '
        f'--imgsz 640 '
        f'--device cpu '
        f'--workers 0 '
        f'--save_dir g:/yoloV13/runs/stage1_incremental'
    )
    if not run_cmd(stage1_cmd):
        return
    
    # æ­¥éª¤4ï¼šå¯¼å‡ºROIï¼ˆè¿™é‡Œéœ€è¦å®ç°å¯¼å‡ºè„šæœ¬ï¼Œæš‚æ—¶è·³è¿‡ï¼‰
    print("\nğŸ“¦ æ­¥éª¤4ï¼šå¯¼å‡ºROIï¼ˆæš‚æœªå®ç°ï¼Œéœ€æ‰‹åŠ¨è¿è¡Œï¼‰")
    print("   è¯·è¿è¡Œ: python tools/export_rois_from_stage1.py")
    
    # æ­¥éª¤5ï¼šStage2è®­ç»ƒ
    print("\nğŸ¯ æ­¥éª¤5ï¼šStage2åˆ†ç±»è®­ç»ƒï¼ˆä»…speciesï¼‰")
    stage2_cmd = (
        f'python g:/yoloV13/ÂµSHM-YOLO/tools/train_stage2_species_only.py '
        f'--cfg {cfg_path} '
        f'--roi_root g:/yoloV13/ÂµSHM-YOLO/tools/reports '
        f'--epochs 30 '
        f'--batch_size 16 '
        f'--device cpu '
        f'--save_dir g:/yoloV13/runs/stage2_incremental'
    )
    # æš‚æ—¶æ³¨é‡Šæ‰ï¼Œå› ä¸ºéœ€è¦å…ˆå¯¼å‡ºROI
    # if not run_cmd(stage2_cmd):
    #     return
    
    # æ­¥éª¤6ï¼šæ¨ç†éªŒè¯
    print("\nğŸ” æ­¥éª¤6ï¼šæ¨ç†éªŒè¯ï¼ˆæš‚æœªå®ç°ï¼‰")
    print("   è¯·è¿è¡Œ: python tools/infer_stage3_pipeline.py")
    
    print("\nâœ… å¢é‡è®­ç»ƒæµç¨‹å®Œæˆï¼")
    print("="*70)

if __name__ == '__main__':
    main()
```

### ä½¿ç”¨æ–¹æ³•

```powershell
# æ¯æ¬¡å¢åŠ æ–°ç…§ç‰‡åï¼Œè¿è¡Œè¿™ä¸ªè„šæœ¬
cd g:\yoloV13\ÂµSHM-YOLO
python train_incremental.py
```

**å®ƒä¼šè‡ªåŠ¨ï¼š**
1. è¯Šæ–­æ–°æ•°æ®é›†
2. ç”Ÿæˆæ–°çš„train/valåˆ’åˆ†
3. è®­ç»ƒStage1
4. ï¼ˆéœ€è¡¥å……ï¼‰å¯¼å‡ºROI
5. è®­ç»ƒStage2
6. ï¼ˆéœ€è¡¥å……ï¼‰æ¨ç†éªŒè¯

---

## æ€»ç»“ä¸ä¸‹ä¸€æ­¥

### âœ… ä½ ç°åœ¨æœ‰äº†ä»€ä¹ˆ

| æ–‡ä»¶ | åŠŸèƒ½ |
|------|------|
| `tools/diagnose_dataset.py` | æ•°æ®è¯Šæ–­ï¼ˆç»Ÿè®¡åˆ†å¸ƒï¼‰ |
| `models/yolov13_seg_film.py` | YOLOv13åˆ†å‰²+FiLM |
| `tools/train_stage1_yolov13_film.py` | Stage1è®­ç»ƒè„šæœ¬ |
| `tools/train_stage2_species_only.py` | Stage2ç®€åŒ–ç‰ˆï¼ˆå•å¤´ï¼‰ |
| `train_incremental.py` | ä¸€é”®å¢é‡è®­ç»ƒ |

### âš ï¸ è¿˜éœ€è¦è¡¥å……çš„

1. **ROIå¯¼å‡ºè„šæœ¬**ï¼šä»Stage1çš„best.ptå¯¼å‡ºROIå›¾åƒå’Œrois.json
2. **æ¨ç†è„šæœ¬é€‚é…**ï¼šè®©`infer_stage3_pipeline.py`å…¼å®¹ç®€åŒ–ç‰ˆStage2
3. **å¯è§†åŒ–è„šæœ¬**ï¼šæŸ¥çœ‹è®­ç»ƒæ•ˆæœ

### ğŸ“ ç»™ä½ çš„AIåŠ©æ‰‹çš„æŒ‡ä»¤æ¨¡æ¿

```
è¯·å¸®æˆ‘å®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š

æ–‡ä»¶ä½ç½®ï¼šg:/yoloV13/ÂµSHM-YOLO/tools/export_rois_from_stage1.py

åŠŸèƒ½ï¼š
1. åŠ è½½ Stage1 çš„ best.pt æƒé‡
2. å¯¹ samples/images/train å’Œ samples/images/val çš„æ‰€æœ‰å›¾åƒæ¨ç†
3. å¯¹æ¯ä¸ªæ£€æµ‹åˆ°çš„å®ä¾‹ï¼š
   - æå–ROIï¼ˆæ ¹æ®maskçš„bboxè£å‰ªï¼Œpadding=10åƒç´ ï¼‰
   - ä¿å­˜ä¸º tools/reports/rois/{split}/{image_id}_{inst_idx}.jpg
4. ç”Ÿæˆ tools/reports/rois.jsonï¼Œæ ¼å¼ï¼š
   {
     "train": [
       {
         "roi_path": "rois/train/1_0.jpg",
         "species": 0,
         "cell_org": 7,
         ...
       }
     ],
     "val": [...]
   }

ä¾èµ–ï¼š
- ä½¿ç”¨ models/yolov13_seg_film.py çš„ YOLOv13SegFiLM æ¨¡å‹
- ä½¿ç”¨ datasets/unified_seg_dataset.py åŠ è½½åŸå›¾
- GTæ ‡ç­¾ä» samples/labels/{split}/*.txt è¯»å–

è¾“å‡ºï¼š
- ROIå›¾åƒä¿å­˜åœ¨ tools/reports/rois/{split}/
- rois.json ä¿å­˜åœ¨ tools/reports/rois.json
```

### ğŸ¯ å¿«é€ŸéªŒè¯æµç¨‹ï¼ˆä¸ç”¨ç­‰å®Œæ•´è®­ç»ƒï¼‰

```powershell
# 1. æ•°æ®è¯Šæ–­ï¼ˆ1åˆ†é’Ÿï¼‰
python tools\diagnose_dataset.py

# 2. ç”Ÿæˆåˆ’åˆ†ï¼ˆ1åˆ†é’Ÿï¼‰
python tools\make_fixed_split.py --data_root g:\yoloV13\ÂµSHM-YOLO\samples --val_ratio 0.2

# 3. å¿«é€Ÿè®­ç»ƒ1ä¸ªepochéªŒè¯æµç¨‹ï¼ˆ5åˆ†é’Ÿï¼‰
python tools\train_stage1_yolov13_film.py --epochs 1 --batch_size 2 --imgsz 256 --device cpu --workers 0

# 4. æŸ¥çœ‹è¾“å‡º
dir g:\yoloV13\runs\stage1_film_50imgs
```

---

**ç°åœ¨ä½ å¯ä»¥ï¼š**
1. æŠŠä¸Šé¢çš„ä»£ç æ–‡ä»¶åˆ›å»ºå¥½
2. è¿è¡Œ `diagnose_dataset.py` çœ‹çœ‹50å¼ å›¾çš„åˆ†å¸ƒ
3. å¦‚æœYOLOv13å¯¼å…¥å¤±è´¥ï¼Œå®ƒä¼šè‡ªåŠ¨é™çº§åˆ°SimpleSegNetFiLM
4. æŠŠ"ROIå¯¼å‡ºè„šæœ¬"çš„éœ€æ±‚ç»™å…¶ä»–AIï¼Œè®©å®ƒå¸®ä½ å®ç°

**éœ€è¦æˆ‘è¿›ä¸€æ­¥ç»†åŒ–å“ªä¸ªéƒ¨åˆ†å—ï¼Ÿ** ğŸš€