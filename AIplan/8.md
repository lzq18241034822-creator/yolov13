太好了，节奏很稳！你已经把 Stage1 分割（实例多通道 + µScale）和 Stage2 Teacher/Student 蒸馏链条跑通了。下一步我们先把“整条推理链（Stage3 规则 + 参数 + 可视化 + JSON）”搭起来，用你当前已有的模型产出“可发表级”的端到端结果。这样即使数据还在扩充，你也能边跑结果边发现问题、调整策略。

本步目标
- 从原图→Stage1 分割（用你当前 best_stage1.pt 简易分割网络）→导出实例 masks 与 ROI；
- 用 Student（best_student.pt）对每个 ROI 做 5 头分类；
- 执行硬规则检查与“冲突→疑似降级”（0..6→31..37），输出 violations；
- 计算 10 个物理参数（以 µm/µm²/mm² 为单位），写入 JSON；
- 生成叠加可视化（掩膜+边框+5头标签+降级提示），一张图一张图保存；
- 支持安全模式（Windows/CPU 无 DataLoader，多线程禁用），保证稳定。

你将新增的文件
- stage3/rule_engine.py：加载 YAML 规则 + 硬规则检查 + 疑似降级
- stage3/param_calc.py：10 个参数计算（单位换算）
- utils/vis_overlay.py：叠加可视化（mask/框/文字）
- tools/infer_stage3_pipeline.py：一键推理脚本（图→mask→ROI→Student分类→规则→参数→JSON+可视化）

1) 规则引擎：stage3/rule_engine.py
- 按 YAML species_morphology_rules 检查 required/forbidden；
- 若冲突且 species ∈ 0..6，则降级到 31..37；记录 violations。

```python
# stage3/rule_engine.py
# -*- coding: utf-8 -*-
from typing import Dict, List, Any

DEMOTION_MAP = {0:31, 1:32, 2:33, 3:34, 4:35, 5:36, 6:37}

def load_rules_from_cfg(cfg: dict) -> List[dict]:
    re_cfg = cfg.get('stage3_integration', {}).get('rule_engine', {})
    if not re_cfg.get('enabled', False):
        return []
    return re_cfg.get('species_morphology_rules', [])

def check_one(ids5: Dict[str,int], rules: List[dict]) -> Dict[str, Any]:
    """ ids5: {'species':g, 'cell_org':g, 'shape':g, 'flagella':g, 'chloroplast':g} 全局ID """
    sp = ids5['species']; co = ids5['cell_org']; sh = ids5['shape']; fl = ids5['flagella']
    violations=[]
    for r in rules:
        if r.get('species') != sp: 
            continue
        req = r.get('required', {})
        forb = r.get('forbidden', {})
        # required
        for k, vals in req.items():
            v = {'cell_org':co, 'shape':sh, 'flagella':fl}.get(k, None)
            if v is not None and v not in vals:
                violations.append(f"required: {k}={v} not in {vals}")
        # forbidden
        for k, vals in forb.items():
            v = {'cell_org':co, 'shape':sh, 'flagella':fl}.get(k, None)
            if v is not None and v in vals:
                violations.append(f"forbidden: {k}={v} in {vals}")
    passed = (len(violations) == 0)
    return {'passed': passed, 'violations': violations}

def apply_demotion_if_needed(ids5: Dict[str,int], rule_result: Dict[str,Any]) -> Dict[str,int]:
    """ 如果冲突且物种在0..6，则降级到对应不确定类 """
    if rule_result['passed']:
        return ids5
    sp = ids5['species']
    if sp in DEMOTION_MAP:
        ids5 = dict(ids5)  # copy
        ids5['species'] = DEMOTION_MAP[sp]
    return ids5
```

2) 形态参数计算：stage3/param_calc.py
- 以实例 mask 计算面积/周长/长短轴/紧致度/椭圆 IoU 等（单位换算）；
- 图级参数：cell_density、aggregation_degree、size_uniformity、orientation_orderliness 等。

```python
# stage3/param_calc.py
# -*- coding: utf-8 -*-
import cv2
import numpy as np
from typing import Dict, List, Any, Tuple
import math

def mask_area_perimeter(mask_bin: np.ndarray) -> Tuple[float, float]:
    # mask_bin: (H,W) {0,1}
    area_px = float(mask_bin.sum())
    contours, _ = cv2.findContours(mask_bin.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    perim_px = 0.0
    for cnt in contours:
        perim_px += cv2.arcLength(cnt, True)
    return area_px, perim_px

def major_minor_axis(mask_bin: np.ndarray) -> Tuple[float, float, float]:
    # 返回: major_px, minor_px, angle_deg（长轴方向角）
    cnts, _ = cv2.findContours(mask_bin.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts or len(cnts[0]) < 5:
        return 0.0, 0.0, 0.0
    cnt = max(cnts, key=cv2.contourArea)
    if len(cnt) < 5:
        rect = cv2.minAreaRect(cnt)
        (w,h) = rect[1]
        a = max(w,h); b = min(w,h); ang = rect[2]
        return a, b, ang
    ell = cv2.fitEllipse(cnt)
    (cx,cy), (MA,ma), angle = ell  # 注意OpenCV返回MA>=ma
    return MA, ma, angle

def compactness(area_px: float, perim_px: float) -> float:
    if perim_px <= 1e-6:
        return 0.0
    return float((4 * math.pi * area_px) / (perim_px ** 2))

def ellipse_iou(mask_bin: np.ndarray) -> float:
    cnts, _ = cv2.findContours(mask_bin.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts: return 0.0
    cnt = max(cnts, key=cv2.contourArea)
    if len(cnt) < 5: return 0.0
    H, W = mask_bin.shape[:2]
    ell = cv2.fitEllipse(cnt)
    ell_mask = np.zeros_like(mask_bin, dtype=np.uint8)
    cv2.ellipse(ell_mask, ell, 1, -1)
    inter = (ell_mask & mask_bin).sum()
    union = (ell_mask | mask_bin).sum()
    if union == 0: return 0.0
    return float(inter / union)

def green_channel_index(image_bgr: np.ndarray, mask_bin: np.ndarray) -> float:
    # 绿通量简单指标：G / 255 在mask内像素平均
    g = image_bgr[...,1].astype(np.float32) / 255.0
    m = mask_bin.astype(bool)
    if m.sum() == 0: return 0.0
    return float(g[m].mean())

def nearest_neighbor_cv(centroids: List[Tuple[float,float]]) -> float:
    # 计算最近邻距离的变异系数 CV
    if len(centroids) < 2: return 0.0
    C = np.array(centroids, dtype=np.float32)
    dists=[]
    for i in range(len(C)):
        di = np.sqrt(((C[i] - C[np.arange(len(C)) != i])**2).sum(axis=1))
        if len(di) == 0: continue
        dists.append(di.min())
    if not dists: return 0.0
    d = np.array(dists)
    if d.mean() <= 1e-6: return 0.0
    return float(d.std(ddof=1) / d.mean())

def area_cv(areas: List[float]) -> float:
    if len(areas) < 2: return 0.0
    a = np.array(areas, dtype=np.float64)
    if a.mean() <= 1e-6: return 0.0
    return float(a.std(ddof=1) / a.mean())

def nematic_order_parameter(angles_deg: List[float]) -> float:
    # S = <cos(2(theta - theta0))> 最大值的近似，这里简化用平均 |cos(2θ)| 
    if not angles_deg: return 0.0
    th = np.deg2rad(np.array(angles_deg, dtype=np.float32))
    s = np.abs(np.cos(2*th)).mean()
    return float(s)

def compute_image_parameters(image_bgr: np.ndarray,
                             inst_masks: List[np.ndarray],
                             pixel_size_um: float) -> Dict[str,float]:
    # 实例级指标
    areas_px=[]; perims_px=[]; majors_px=[]; minors_px=[]; angles=[]
    centroids=[]
    for m in inst_masks:
        area_px, perim_px = mask_area_perimeter(m)
        A, B, ang = major_minor_axis(m)
        areas_px.append(area_px); perims_px.append(perim_px)
        majors_px.append(A); minors_px.append(B); angles.append(ang)
        ys, xs = np.where(m>0)
        if len(xs)>0:
            centroids.append((float(xs.mean()), float(ys.mean())))
    # 单位换算
    px = pixel_size_um
    areas_um2 = (np.array(areas_px) * (px**2)).tolist()
    perims_um = (np.array(perims_px) * px).tolist()
    majors_um = (np.array(majors_px) * px).tolist()
    minors_um = (np.array(minors_px) * px).tolist()

    # 图像物理面积（mm^2）
    H, W = image_bgr.shape[:2]
    area_mm2 = (W*px/1000.0) * (H*px/1000.0)
    density = len(inst_masks) / area_mm2 if area_mm2 > 0 else 0.0

    # 其它
    comp_vals = [compactness(a,p) if p>0 else 0.0 for a,p in zip(areas_px, perims_px)]
    ell_iou = [ellipse_iou(m) for m in inst_masks]
    green_idx = np.mean([green_channel_index(image_bgr, m) for m in inst_masks]) if inst_masks else 0.0

    params = {
        'cell_density': float(density),
        'aspect_ratio': float(np.mean([(ma/(mi+1e-6)) if mi>0 else 0.0 for ma,mi in zip(majors_px, minors_px)]) if inst_masks else 0.0),
        'boundary_complexity': float(np.mean([(p**2)/(4*math.pi*a + 1e-6) if a>0 else 0.0 for a,p in zip(areas_px, perims_px)]) if inst_masks else 0.0),
        'fractal_dimension': 0.0,  # 可选实现 box-counting，先置0
        'compactness': float(np.mean(comp_vals) if comp_vals else 0.0),
        'ellipse_similarity': float(np.mean(ell_iou) if ell_iou else 0.0),
        'chlorophyll_content': float(green_idx),
        'aggregation_degree': float(nearest_neighbor_cv(centroids)),
        'size_uniformity': float(area_cv(areas_um2)),
        'orientation_orderliness': float(nematic_order_parameter(angles)),
    }
    return params
```

3) 可视化叠加：utils/vis_overlay.py
- 在原图上叠加每个实例 mask边界、bbox、5头标签、是否降级与 violations 简述。

```python
# utils/vis_overlay.py
# -*- coding: utf-8 -*-
import cv2
import numpy as np
from typing import List, Dict, Any

def color_palette(i: int):
    colors = [(255,0,0),(0,255,0),(0,0,255),(255,255,0),(255,0,255),(0,255,255)]
    return colors[i % len(colors)]

def draw_instance_overlay(img: np.ndarray,
                          masks: List[np.ndarray],
                          rois: List[Dict[str,Any]],
                          labels: List[Dict[str,Any]],
                          rule_infos: List[Dict[str,Any]]):
    out = img.copy()
    H, W = out.shape[:2]
    for i, m in enumerate(masks):
        c = color_palette(i)
        cnts, _ = cv2.findContours(m.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(out, cnts, -1, c, 2)
        # bbox
        ys, xs = np.where(m>0)
        if len(xs)>0:
            x0,x1 = xs.min(), xs.max()
            y0,y1 = ys.min(), ys.max()
            cv2.rectangle(out, (x0,y0), (x1,y1), c, 2)
        # text
        if i < len(labels):
            lab = labels[i]
            sp = lab['species_name']; co = lab['cell_org_name']; sh = lab['shape_name']; fl = lab['flagella_name']; ch = lab['chloroplast_name']
            txt = f"{sp}|{co}|{sh}|{fl}|{ch}"
            if i < len(rule_infos) and not rule_infos[i]['passed']:
                txt += " [demoted]"
            y_txt = (ys.min() if len(ys)>0 else 10) - 10
            y_txt = max(10, y_txt)
            cv2.putText(out, txt, (10, y_txt), cv2.FONT_HERSHEY_SIMPLEX, 0.5, c, 1, cv2.LINE_AA)
    return out
```

4) 一键推理脚本：tools/infer_stage3_pipeline.py
- 读 YAML 和 images/{split}；
- 运行 Stage1 分割（加载 tools/reports/best_stage1.pt 的 SimpleSegNetFiLM），阈值化多通道输出得到实例 masks；
- 裁 ROI（可复用你现有 roi_export），用 best_student.pt 分类 5 头；
- 规则检查 + 降级；
- 计算参数；
- 写 JSON + 可视化。

注意：为了快速对接，我们这里用你当前“简易分割网络”的 best_stage1.pt。如果你想直接切 YOLOv13 seg 头，下一步我再给“最小侵入补丁”。

保存为 tools/infer_stage3_pipeline.py
```python
# -*- coding: utf-8 -*-
import os, json, glob, argparse
import numpy as np
import cv2
import torch
from ruamel.yaml import YAML

from models.simple_seg_film import SimpleSegNetFiLM
from models.multitask_heads import MultiHeadClassifier
from stage3.rule_engine import load_rules_from_cfg, check_one, apply_demotion_if_needed
from stage3.param_calc import compute_image_parameters
from utils.vis_overlay import draw_instance_overlay

def imread_unicode(path):
    data = np.fromfile(path, dtype=np.uint8)
    img = cv2.imdecode(data, cv2.IMREAD_COLOR)
    return img

def rasterize_logits_to_instances(logits: torch.Tensor, thr=0.5, min_area=10):
    # logits: (1,C,H,W)
    probs = torch.sigmoid(logits).detach().cpu().numpy()[0]  # (C,H,W)
    masks=[]
    for c in range(probs.shape[0]):
        m = (probs[c] > thr).astype(np.uint8)
        if m.sum() >= min_area:
            masks.append(m)
    return masks

def crop_rois_from_masks(img_bgr, masks, expand=1.2, min_size=16):
    H, W = img_bgr.shape[:2]
    crops=[]; boxes=[]
    for m in masks:
        ys, xs = np.where(m>0)
        if len(xs)==0: continue
        x0,x1 = xs.min(), xs.max(); y0,y1 = ys.min(), ys.max()
        w = x1 - x0; h = y1 - y0
        cx = (x0 + x1)/2; cy = (y0 + y1)/2
        w2 = int(w*expand/2); h2=int(h*expand/2)
        x0e = max(0, int(cx - w2)); x1e = min(W, int(cx + w2))
        y0e = max(0, int(cy - h2)); y1e = min(H, int(cy + h2))
        if (x1e-x0e) < min_size or (y1e-y0e) < min_size:
            continue
        crop = img_bgr[y0e:y1e, x0e:x1e]
        crops.append(crop); boxes.append([x0e,y0e,x1e,y1e])
    return crops, boxes

def normalize_img_rgb(img, mean, std, size=224):
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (size,size), interpolation=cv2.INTER_LINEAR)
    img = img.astype(np.float32)/255.0
    img = (img - np.array(mean).reshape(1,1,3)) / np.array(std).reshape(1,1,3)
    img = img.transpose(2,0,1)
    return torch.from_numpy(img).unsqueeze(0)  # (1,3,H,W)

def id_to_name(cfg, gid: int):
    names = cfg['classes']['names']; names_zh = cfg['classes']['names_zh']
    gid = int(gid)
    return names.get(gid, str(gid)), names_zh.get(gid, str(gid))

def build_label_names(cfg, ids5_global):
    # ids5_global: dict with global IDs
    def name_of(gid): return cfg['classes']['names_zh'].get(int(gid), str(gid))
    return {
        'species_name': name_of(ids5_global['species']),
        'cell_org_name': name_of(ids5_global['cell_org']),
        'shape_name': name_of(ids5_global['shape']),
        'flagella_name': name_of(ids5_global['flagella']),
        'chloroplast_name': name_of(ids5_global['chloroplast']),
    }

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--cfg", required=True)
    ap.add_argument("--split_dir", type=str, default=None, help="如提供，则仅处理 splits/val.txt 内样本")
    ap.add_argument("--data_root", required=True)
    ap.add_argument("--stage1_weights", required=True, help="tools/reports/best_stage1.pt")
    ap.add_argument("--student_weights", required=True, help="runs/stage2_student/best_student.pt")
    ap.add_argument("--out_dir", type=str, default="runs/infer_stage3")
    ap.add_argument("--imgsz", type=int, default=640)
    ap.add_argument("--device", type=str, default="cpu")
    ap.add_argument("--thr", type=float, default=0.5)
    args = ap.parse_args()

    os.makedirs(args.out_dir, exist_ok=True)
    yaml = YAML()
    with open(args.cfg, 'r', encoding='utf-8') as f:
        cfg = yaml.load(f)

    data_root = args.data_root
    img_dir = os.path.join(data_root, 'images', 'val')  # 默认 val；如 split_dir 提供，按列表过滤
    imgs=[]
    for ext in ("*.jpg","*.jpeg","*.png","*.bmp","*.tif","*.tiff"):
        imgs.extend(glob.glob(os.path.join(img_dir, ext)))
    imgs = sorted(imgs)
    allowed = None
    if args.split_dir:
        val_list = os.path.join(args.split_dir, "val.txt")
        if os.path.exists(val_list):
            with open(val_list, 'r', encoding='utf-8') as f:
                allowed = set([ln.strip() for ln in f if ln.strip()])
    if allowed is not None:
        imgs = [p for p in imgs if os.path.splitext(os.path.basename(p))[0] in allowed]

    device = torch.device(args.device)
    # 加载 Stage1 简易分割模型
    model_seg = SimpleSegNetFiLM(base_ch=32, out_ch=1, base_pixel_size=cfg['microscope']['pixel_size_um']).to(device)
    ckpt = torch.load(args.stage1_weights, map_location=device)
    model_seg.load_state_dict(ckpt['model'] if 'model' in ckpt else ckpt)
    model_seg.eval()

    # 加载 Student 多头分类器
    model_cls = MultiHeadClassifier(pretrained=False).to(device)
    model_cls.load_state_dict(torch.load(args.student_weights, map_location=device))
    model_cls.eval()

    rules = load_rules_from_cfg(cfg)
    mean = cfg['dataset_stats']['mean']; std = cfg['dataset_stats']['std']
    px_um = float(cfg['microscope']['pixel_size_um'])

    all_results = []
    for ip in imgs:
        img_bgr = imread_unicode(ip)
        if img_bgr is None:
            print(f"[warn] read fail: {ip}"); continue
        # 分割
        im_res = cv2.resize(img_bgr, (args.imgsz,args.imgsz))
        # 假定 pixel_scale batch为1
        with torch.no_grad():
            x = torch.from_numpy(cv2.cvtColor(im_res, cv2.COLOR_BGR2RGB)).permute(2,0,1).float().div(255.0).unsqueeze(0).to(device)
            logits = model_seg(x, pixel_scale=torch.tensor([px_um], dtype=torch.float32, device=device))
        masks = rasterize_logits_to_instances(logits, thr=args.thr, min_area=20)

        # 计算 ROI & 分类
        crops, boxes = crop_rois_from_masks(im_res, masks, expand=1.2, min_size=16)
        dets=[]
        labels_for_vis=[]
        rule_infos=[]
        for idx, crop in enumerate(crops):
            inp = normalize_img_rgb(crop, mean, std, size=224).to(device)
            with torch.no_grad():
                outs = model_cls(inp)
            # 五头预测（取 argmax -> 全局ID）
            sp = int(outs['species'].argmax(dim=1).item())
            co_local = int(outs['cell_org'].argmax(dim=1).item())
            sh_local = int(outs['shape'].argmax(dim=1).item())
            fl_local = int(outs['flagella'].argmax(dim=1).item())
            ch_local = int(outs['chloroplast'].argmax(dim=1).item())
            # 映射到全局ID
            local_to_global = {
                'cell_org': {0:7,1:8,2:9,3:44},
                'shape': {0:12,1:13,2:14,3:15,4:16,5:17,6:18,7:19,8:20,9:21},
                'flagella': {0:22,1:23,2:24,3:25,4:26},
                'chloroplast': {0:27,1:28,2:29,3:30},
            }
            ids5_global = {'species': sp,
                           'cell_org': local_to_global['cell_org'][co_local],
                           'shape': local_to_global['shape'][sh_local],
                           'flagella': local_to_global['flagella'][fl_local],
                           'chloroplast': local_to_global['chloroplast'][ch_local]}
            # 规则检查与降级
            rc = check_one(ids5_global, rules)
            ids5_final = apply_demotion_if_needed(ids5_global, rc)

            # 记录
            dets.append({
                'bbox_xyxy': [int(x) for x in boxes[idx]],
                'ids5_raw': ids5_global,
                'ids5_final': ids5_final,
                'rule': rc
            })
            labels_for_vis.append(build_label_names(cfg, ids5_final))
            rule_infos.append(rc)

        # 计算参数（用原图大小换算像素尺度更准确，这里用im_res尺寸 + 相同px_um近似）
        params = compute_image_parameters(im_res, masks, pixel_size_um=px_um)

        # 可视化
        vis = draw_instance_overlay(im_res, masks, dets, labels_for_vis, rule_infos)
        out_vis = os.path.join(args.out_dir, f"{os.path.splitext(os.path.basename(ip))[0]}_overlay.jpg")
        cv2.imwrite(out_vis, vis)

        all_results.append({
            'image_path': ip,
            'pixel_size_um': px_um,
            'detections': dets,
            'parameters': params,
            'overlay_path': out_vis
        })

    out_json = os.path.join(args.out_dir, "predictions.json")
    with open(out_json, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    print(f"[OK] saved JSON: {out_json}")
    print(f"[OK] overlays in: {args.out_dir}")
if __name__ == "__main__":
    main()
```

如何运行
- 先准备：
  - Stage1 简易分割权重：tools/reports/best_stage1.pt
  - Stage2 学生权重：runs/stage2_student/best_student.pt
- 推理（建议先在 val split 上）：
  - python tools/infer_stage3_pipeline.py --cfg yolov13_transformer_unified_v2_1.yaml --data_root samples --split_dir µSHM-YOLO/splits --stage1_weights tools/reports/best_stage1.pt --student_weights runs/stage2_student/best_student.pt --out_dir runs/infer_stage3 --device cpu
- 输出：
  - runs/infer_stage3/predictions.json（每图完整结果）
  - runs/infer_stage3/*.jpg（掩膜+5头+降级的叠加图）

验收标准
- predictions.json 有每张图的 detections（bbox/ids5_raw/ids5_final/violations）和 parameters；
- 可视化图叠加显示掩膜轮廓、bbox、5头标签、冲突时的 [demoted] 标识；
- 10 个参数单位正确（密度 cells/mm²；面积/周长/轴长以 µm/µm² 内部计算，最终仅图级参数输出）。

下一步（你确认本步OK后）
- 切换 Stage1 到 YOLOv13 真正的分割头（proto+coeff），把我们统一数据 + µScale FiLM 注入到 RepGFPN（P3/P2），并打开 P2/RepGFPN/DCNv3，获得标准 mAP50(M)/APS；
- 将本步的 Student 5头挂回 YOLOv13（一体化 Mask2Morph）：在分割头输出后加 ROI-Align → 5 头（初始化用 best_student.pt），训练时用 CE + KL(Teacher/Student logits）继续蒸馏；再叠加超图（你的仓库已有）与软规则/几何一致性。

说明
- 目前我们用简易分割网络跑端到端 pipeline（Stage3），是为了快速产出“可落地”的完整结果与 JSON。等你切回 YOLOv13 分割头后，tools/infer_stage3_pipeline.py 里替换分割部分即可，其他（Student 分类、规则、参数、可视化）均可复用不变。
- 若你希望这一步同时输出更详细的图级报告（类别分布、冲突矩阵、参数箱线图），我可以在 infer 脚本里加一份 summary 统计。

你先把这个 pipeline 跑一遍，确认 JSON 与叠加图合理。OK 后我们就进入“YOLOv13 seg 头 + neck-FiLM + P2/RepGFPN/DCNv3”的接线训练，让指标切换到标准 mAP50(M)/APS。