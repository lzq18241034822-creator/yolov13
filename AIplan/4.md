好，基础数据管道已经跑通。接下来进入步骤4：把 µScale 像素尺度注入（FiLM 调制）接入你的 YOLOv13 模型，并在颈部 P3/P2 位置生效。这样做改动小、收益稳，后面再视情况扩展到 backbone s3/s4。

本步目标
- 在你的 YOLOv13 模型里接入 µScale（FiLM），让模型感知 pixel_size_um。
- 最小侵入：先对 RepGFPN 颈部输出 P3/P2 做 FiLM 调制（通道一般为 neck 的 out_channels=256，易对接）。
- 改动内容：
  1) 新增通用 FiLM 模块文件（models/uscale_film.py）
  2) 修改 RepGFPN 颈部（models/neck/repgfpn.py 或同等文件）以接受 pixel_scale，并在 P3/P2 注入 FiLM
  3) 修改最外层模型 forward 签名，向 neck 传 pixel_scale
  4) 训练循环把 pixel_scales 传给 model(...)

交付代码与说明
一) 新增文件：models/uscale_film.py
作用：把一个标量的像素尺度（µm/px）经 log_ratio 归一化，映射成每层通道的 FiLM 参数 gamma/beta，并对特征图做 y = x * (1 + gamma) + beta。

请新建 models/uscale_film.py：
```python
# -*- coding: utf-8 -*-
# µScale FiLM conditioning for YOLOv13
import torch
import torch.nn as nn

class PixelScaleNormalizer(nn.Module):
    def __init__(self, base_pixel_size=0.0863, method='log_ratio', eps=1e-8):
        super().__init__()
        self.base = float(base_pixel_size)
        self.method = method
        self.eps = eps

    def forward(self, pixel_scale: torch.Tensor):
        # pixel_scale: (B,) on same device as features
        if self.method == 'log_ratio':
            s = torch.log(pixel_scale.clamp(min=self.eps) / self.base)
        else:
            s = (pixel_scale - self.base) / (self.base + self.eps)
        return s.unsqueeze(-1)  # (B,1)

class FiLM2d(nn.Module):
    def __init__(self, channels: int, base_pixel_size=0.0863, method='log_ratio', hidden=64):
        super().__init__()
        self.norm = PixelScaleNormalizer(base_pixel_size, method=method)
        self.mlp = nn.Sequential(
            nn.Linear(1, hidden),
            nn.SiLU(),
            nn.Linear(hidden, 2 * channels)
        )
        self.channels = channels

    def forward(self, x: torch.Tensor, pixel_scale: torch.Tensor):
        # x: (B, C, H, W), pixel_scale: (B,)
        s = self.norm(pixel_scale)                # (B,1)
        g = self.mlp(s)                           # (B, 2C)
        gamma, beta = torch.chunk(g, 2, dim=-1)   # (B, C), (B, C)
        gamma = gamma.unsqueeze(-1).unsqueeze(-1) # (B, C, 1, 1)
        beta  = beta.unsqueeze(-1).unsqueeze(-1)  # (B, C, 1, 1)
        # 广播到 (B, C, H, W)
        return x * (1 + gamma) + beta
```

二) 修改颈部 RepGFPN：在 P3/P2 输出处注入 FiLM
你的仓库内 neck 可能是 models/neck/repgfpn.py（或类似）。找到 RepGFPN 类的 __init__ 和 forward，并按下述要点改：

- 在 __init__ 中创建两个 FiLM 模块，用于 P3 和 P2（通道使用 neck 的 out_channels，通常 256）。
- 在 forward 返回 P3/P4/P5/P2（若有）之前，调用 film_p3(..., pixel_scale) 和 film_p2(..., pixel_scale)。
- forward 接收 pixel_scale: torch.Tensor | None（(B,)），只有在非空时才应用 FiLM。

示例（请按你文件结构定位插入；变量名可能不同，照着思路改）：
```python
# 文件：models/neck/repgfpn.py 伪示例，按你实际文件修改
import torch
import torch.nn as nn
from models.uscale_film import FiLM2d

class RepGFPN(nn.Module):
    def __init__(self, in_channels=(256, 512, 1024), out_channels=256, add_p2=True, reparam=True, **kwargs):
        super().__init__()
        self.out_channels = out_channels
        self.add_p2 = add_p2
        self.reparam = reparam
        # ... 你原有的RepGFPN构建（top-down / bottom-up / repconv等） ...

        # µScale FiLM for neck outputs
        self.uscale_enabled = True   # 可配
        self.film_p3 = FiLM2d(out_channels, base_pixel_size=0.0863, method='log_ratio')
        if self.add_p2:
            self.film_p2 = FiLM2d(out_channels, base_pixel_size=0.0863, method='log_ratio')

    def forward(self, feats, pixel_scale: torch.Tensor = None):
        """
        feats: list of backbone features (e.g., C3, C4, C5)
        pixel_scale: (B,) or None
        return: list of pyramid features [P3, P4, P5, (P2 if add_p2)]
        """
        # ... 你原有的FPN逻辑，得到 p3, p4, p5（以及 p2 如果 add_p2=True）
        # 假设最终变量名为 p3, p4, p5, p2（根据你的实现调整）

        # 在输出位置注入 FiLM（仅当 pixel_scale 提供且开关开启）
        if self.uscale_enabled and (pixel_scale is not None):
            if p3 is not None:
                p3 = self.film_p3(p3, pixel_scale)
            if self.add_p2 and (p2 is not None):
                p2 = self.film_p2(p2, pixel_scale)

        # 返回列表需与后续 head 对齐
        if self.add_p2:
            return [p3, p4, p5, p2]
        else:
            return [p3, p4, p5]
```

注意：
- out_channels 使用 neck 的输出通道（大多为 256），确保与 p3/p2 的 C 维一致；若你在构建时设置不同维度，按实参匹配 FiLM2d(channels)。
- 如果你的 forward 返回顺序不同（比如 [p2, p3, p4, p5]），就相应调整注入和返回顺序。
- 如果你后续还想在 P4/P5 注入，也可以照此添加 film_p4、film_p5，一起生效。

三) 修改最外层模型，将 pixel_scale 透传给 neck
找到你的模型装配文件（如 models/yolo.py / models/model.py / detect.py 内的 Model 类），把 forward 的签名加上 pixel_scale=None，并在 neck.forward(...) 时传入。

示例（伪代码，按你仓库实际文件改）：
```python
class Model(nn.Module):
    def __init__(self, cfg, ...):
        super().__init__()
        # self.backbone = CSPDarknet(...)
        # self.neck     = RepGFPN(...)
        # self.head     = YoloSegHead(...)

    def forward(self, x, pixel_scale: torch.Tensor = None, **kwargs):
        # x: (B,3,H,W)
        feats = self.backbone(x)                     # list of C3,C4,C5
        pyramids = self.neck(feats, pixel_scale)     # 这里将 pixel_scale 透传给 neck
        out = self.head(pyramids, **kwargs)          # 分割头
        return out
```

如果你的 backbone.forward 也想注入 µScale（s3/s4），等 neck 端稳定后再加；本步先 neck 即可。

四) 训练循环把 pixel_scales 传进 model.forward
你上一步的 DataLoader 已经返回 pixel_scales（(B,)）。在训练 batch 里，images 预处理为 float / RGB / /255 后，调用：
```python
outputs = model(images, pixel_scale=pixel_scales.to(images.device), segments=batch_segments, targets=batch_labels)
```
其中 segments 与 targets 的传递用你仓库已有的接口（如 head 需要）。

五) 配置开关（可选）
- 在 YAML 里，已配置：
  model.pixel_scale_conditioning.enabled = true
  model.pixel_scale_conditioning.method = "log_ratio"
  model.pixel_scale_conditioning.base_pixel_size_um = 0.0863
- 你可以在 RepGFPN.__init__ 读这些配置，决定 uscale_enabled 开关和 base_pixel_size。

六) 快速验证（建议）
- A/B 对比：关掉 uscale_enabled（或不传 pixel_scale）训练 20–30 epoch，记录 mAP50(M)、APS（小目标 AP）、val loss；再打开 µScale 重训相同时长，对比提升幅度（期望 mAP↑0.5~1.5%，APS 提升、面积误差更稳）。
- 跨批次一致性：从不同采集批（若存在）各抽20张做验证，统计两个批次的 mAP 方差（µScale 应降低方差）。

常见坑与排查
- 通道不匹配：FiLM2d 的 channels 必须等于对应特征图的通道数。用 print(p3.shape) 确认 C 是否是 256（或你的 out_channels），否则调整 FiLM2d 的 channels。
- 设备不一致：pixel_scales.to(images.device)，否则会有 device mismatch。
- 空 batch 情况：有时整张图都被 skip 掉，DataLoader 会跳过该图，不会出现在 batch 里；这是预期行为。
- 推理时：detect.py 同样把 pixel_scale 传入 model.forward（从 TXT 头部读取，或用 cfg.microscope.pixel_size_um 回退）。

小目标结构（P2/RepGFPN/DCNv3）开关小提示（本步不强制、可一并打开）
- 你的 YAML 已经有：
  model.stage1_detection.neck.add_p2: true
  model.stage1_detection.neck.reparam: true
  model.stage1_detection.backbone.dcnv3.enabled: true
- 确保构建模型时读取开关，正确创建 P2 分支、RepGFPN 重参数结构和 DCNv3 层。建议先保证 FiLM 接入稳定，再开 DCN（如果 DCN 稳定，直接开也可）。

你接下来要做的事（按 repo 里实际文件对齐）
1) 添加 models/uscale_film.py
2) 修改 models/neck/repgfpn.py（或你的 neck 类所在文件）：
   - __init__ 中实例化 film_p3、film_p2
   - forward(feats, pixel_scale=None) 中在 p3/p2 输出处应用 FiLM
3) 修改你的 Model 类 forward，透传 pixel_scale 给 neck
4) 训练脚本里把 pixel_scales 传给 model(..., pixel_scale=pixel_scales)

完成后，先跑 1 个 epoch 看看能否无错误地前向/反向；再跑 50–100 epoch 做一个 µScale 对比。

下一个步骤预告
- 如果本步 OK，我们继续步骤5：把你仓库里的 P2/RepGFPN/DCNv3 配置完整打开（如果还没），并给出“小目标专项训练建议 + 评估指标脚本”；
- 或者直接进入步骤6：接入 Mask2Morph 一体化五头（先用 GT ROI 训），我会给出 ROI-Align 适配、5头标签映射、loss 聚合的实现骨架。

你先把 µScale FiLM 接进去跑起来（至少 1 个 epoch），有任何报错贴出来我来帮你对齐你仓库的具体类名/路径。