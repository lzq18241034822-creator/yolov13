太棒了！Stage3 评测与报告已经闭环。为了把“群体结构（单/双/四/多>4）”再稳一层，同时不改动现有模型，这一步我们先做“Stage3 超图（邻近聚团）离线细化”。它不依赖YOLOv13内部结构，直接对 predictions.json 进行基于距离的超边（pair/quartet/multi）归并与重赋值，能明显提升 cell_organization 的一致性，是论文里的一个独立模块（可视化对比也更直观）。

本步目标
- 从 predictions.json 读取每张图的实例 bbox → 计算中心点与尺度；
- 构建邻近图，做连通分量（无监督密度聚团）；对每个分量按实例数重赋值 cell_organization：
  - 1 → 单细胞（7）；2 → 双细胞（8）；4 → 四细胞（9）；>4 → 多细胞（44）
- 与 Student 原预测合并（优先按“高置信邻近证据”更新），并保持物种等其它头不变；
- 输出 refined_predictions.json 与超图叠加可视化，更新评测 summary；
- 可切换阈值（eps因子）与最小尺寸门槛（min_size_px）。

你将新增的文件
- stage3/hypergraph_refine.py：邻近聚团+重赋值（无依赖、轻量）
- tools/refine_hypergraph_stage3.py：一键对 predictions.json 做超图细化并输出可视化
- 可选：在 README 增补“Stage3 超图细化”章节（命令、参数、前后对比）

一、核心实现：stage3/hypergraph_refine.py
- 无需训练，基于对象中心的邻近图做连通分量；简单可靠；
- eps 像素阈值采用“中位实例尺寸 × 因子”（默认1.6），适配不同视野；
- 群体映射：size=1→7，2→8，4→9，>4→44。

```python
# stage3/hypergraph_refine.py
# -*- coding: utf-8 -*-
from typing import List, Dict, Any, Tuple
import numpy as np

CELLORG_MAP = {1: 7, 2: 8, 4: 9}  # 其它走 44 (multicellular_gt4)

def _centroid_from_box(box):
    x0,y0,x1,y1 = box
    return ((x0+x1)/2.0, (y0+y1)/2.0)

def _size_from_box(box):
    x0,y0,x1,y1 = box
    return max(1.0, np.sqrt(max(1.0,(x1-x0)*(y1-y0))))

def _build_graph(centroids: List[Tuple[float,float]], eps: float):
    n = len(centroids)
    if n == 0:
        return []
    C = np.array(centroids, dtype=np.float32)  # (n,2)
    # 简易邻接（阈值内连边）
    adj = [[] for _ in range(n)]
    for i in range(n):
        di = np.sqrt(((C[i] - C)**2).sum(axis=1))
        nbrs = np.where(di <= eps)[0].tolist()
        for j in nbrs:
            if j != i:
                adj[i].append(j)
                adj[j].append(i)
    # 连通分量
    visited = [False]*n
    comps = []
    for i in range(n):
        if visited[i]:
            continue
        stack=[i]; visited[i]=True; comp=[i]
        while stack:
            u=stack.pop()
            for v in adj[u]:
                if not visited[v]:
                    visited[v]=True
                    stack.append(v); comp.append(v)
        comps.append(comp)
    return comps

def refine_cell_org_by_proximity(detections: List[Dict[str,Any]],
                                 eps_factor: float = 1.6,
                                 min_size_px: float = 6.0) -> List[int]:
    """
    detections: 每个包含 {'bbox_xyxy': [x0,y0,x1,y1], 'ids5_final': {...}}
    return: 新的 cell_organization 全局ID 列表（按输入顺序）
    """
    if len(detections)==0:
        return []
    boxes = [d['bbox_xyxy'] for d in detections]
    sizes = [max(min_size_px, _size_from_box(b)) for b in boxes]
    med_size = float(np.median(sizes))
    eps = max(min_size_px, med_size * eps_factor)

    centroids = [_centroid_from_box(b) for b in boxes]
    comps = _build_graph(centroids, eps)

    # 初值用原预测
    new_cell_org = [d['ids5_final']['cell_org'] if 'ids5_final' in d else d.get('cell_org', 7)
                    for d in detections]

    for comp in comps:
        k = len(comp)
        if k in CELLORG_MAP:
            new_val = CELLORG_MAP[k]
        else:
            new_val = 44  # >4
        for idx in comp:
            new_cell_org[idx] = new_val

    return new_cell_org
```

二、离线细化脚本：tools/refine_hypergraph_stage3.py
- 读 runs/infer_stage3/predictions.json；
- 对每张图更新每个实例 ids5_final.cell_org 为超图细化结果（仅 cell_org，其他头/物种保持不变）；
- 输出 refined_predictions.json 与新 overlay（可复用你已改为中文字体+半透明的可视化）。

```python
# tools/refine_hypergraph_stage3.py
# -*- coding: utf-8 -*-
import os, json, argparse
import numpy as np
import cv2
from ruamel.yaml import YAML

from stage3.hypergraph_refine import refine_cell_org_by_proximity
from utils.vis_overlay import draw_instance_overlay

def imread_unicode(path):
    data = np.fromfile(path, dtype=np.uint8)
    return cv2.imdecode(data, cv2.IMREAD_COLOR)

def build_label_names(cfg, ids5_global):
    def name_of(gid): return cfg['classes']['names_zh'].get(int(gid), str(gid))
    return {
        'species_name': name_of(ids5_global['species']),
        'cell_org_name': name_of(ids5_global['cell_org']),
        'shape_name': name_of(ids5_global['shape']),
        'flagella_name': name_of(ids5_global['flagella']),
        'chloroplast_name': name_of(ids5_global['chloroplast']),
    }

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--cfg", required=True)
    ap.add_argument("--pred_json", required=True, help="原始 predictions.json")
    ap.add_argument("--out_dir", type=str, default="runs/infer_stage3_hg")
    ap.add_argument("--eps_factor", type=float, default=1.6)
    ap.add_argument("--min_size_px", type=float, default=6.0)
    ap.add_argument("--imgsz", type=int, default=640)
    args = ap.parse_args()

    os.makedirs(args.out_dir, exist_ok=True)
    yaml = YAML()
    with open(args.cfg, 'r', encoding='utf-8') as f:
        cfg = yaml.load(f)

    with open(args.pred_json, 'r', encoding='utf-8') as f:
        preds = json.load(f)

    refined=[]
    for rec in preds:
        img_path = rec['image_path']
        img = imread_unicode(img_path)
        if img is None: 
            continue
        im_res = cv2.resize(img, (args.imgsz,args.imgsz), interpolation=cv2.INTER_LINEAR)
        dets = rec.get('detections', [])
        # 细化 cell_org
        new_cell_org = refine_cell_org_by_proximity(dets, eps_factor=args.eps_factor, min_size_px=args.min_size_px)
        # 更新 ids5_final
        for i, d in enumerate(dets):
            if i < len(new_cell_org):
                d['ids5_final']['cell_org'] = int(new_cell_org[i])

        # 可视化：叠加（这里用矩形框mask近似，若需要更精确可在 infer_stage3 时保存实例mask路径）
        masks = []
        H, W = im_res.shape[:2]
        for d in dets:
            m = np.zeros((H,W), dtype=np.uint8)
            x0,y0,x1,y1 = d['bbox_xyxy']
            x0,y0 = max(0,x0), max(0,y0); x1,y1 = min(W-1,x1), min(H-1,y1)
            m[y0:y1, x0:x1] = 1
            masks.append(m)
        labels_for_vis=[build_label_names(cfg, d['ids5_final']) for d in dets]
        rule_infos=[{'passed': True, 'violations': []} for _ in dets]  # 可选显示

        vis = draw_instance_overlay(im_res, masks, dets, labels_for_vis, rule_infos)
        out_vis = os.path.join(args.out_dir, f"{os.path.splitext(os.path.basename(img_path))[0]}_overlay_hg.jpg")
        cv2.imwrite(out_vis, vis)

        rec2 = dict(rec)
        rec2['detections'] = dets
        rec2['overlay_hg'] = out_vis
        refined.append(rec2)

    out_json = os.path.join(args.out_dir, "refined_predictions.json")
    with open(out_json, 'w', encoding='utf-8') as f:
        json.dump(refined, f, ensure_ascii=False, indent=2)
    print(f"[OK] saved refined JSON: {out_json}")
    print(f"[OK] overlays in: {args.out_dir}")

if __name__ == "__main__":
    main()
```

三、如何运行
- 从你已生成的 Stage3 输出继续：
  - python tools/refine_hypergraph_stage3.py --cfg µSHM-YOLO\yolov13_transformer_unified_v2_1.yaml --pred_json g:\yoloV13\runs\infer_stage3\predictions.json --out_dir g:\yoloV13\runs\infer_stage3_hg --imgsz 640 --eps_factor 1.6
- 重新评测（对 refined JSON）：
  - python µSHM-YOLO\tools\eval_stage3_report.py --data_root µSHM-YOLO\samples --pred_json g:\yoloV13\runs\infer_stage3_hg\refined_predictions.json --imgsz 640 --iou_thr 0.5 --save_dir g:\yoloV13\runs\eval_stage3_hg --plot 1
- 关注指标变化：
  - cell_org 混淆矩阵（cm_cell_org.png）是否更对角；
  - demote_rate 可能变化（规则冲突也可能降低）；
  - 其他头不受影响（species/shape/flagella/chloro）。

四、可选调参
- eps_factor（默认1.6）：越大越容易把相邻实例并入同一群体；若误并，多试 1.3 ~ 2.0；
- min_size_px：对极小 bbox 的鲁棒性门槛（避免单像素扰动给出错误聚团）；
- 你也可以加“组件内强一致约束”：当组件大小=4时，若有实例预测非 quartet，可统一改为 quartet。

五、整体进度盘点（10步路线）
- 1 数据/质检/像素尺度统一：已完成
- 2 Stage1 基线分割（简易网）+ 同步增强：已完成
- 3 µScale 注入（FiLM）：已完成（简易网），待迁移到 neck
- 4 小目标结构（P2/RepGFPN/DCNv3）：未做（下一阶段在 YOLOv13 中开启）
- 5 Mask2Morph 一体化（ROI-Align + 5头）：未挂回 YOLOv13（Student/Teacher ROI 已完成）
- 6 两段式蒸馏（Teacher/Student）：已完成（ROI层面）
- 7 超图群体推理：离线细化本步完成；后续可把该逻辑移入 YOLOv13 内部或做学习版
- 8 软规则正则（训练期）+ 推理降级：推理降级已做；训练期软规则正则未做
- 9 几何参数双重监督（训练期）：未做（推理参数已做）
- 10 端到端评测与报告：已完成（Stage3），可继续完善PR曲线等

阶段性完成度（粗估）
- 功能闭环（数据→分割→分类→规则→参数→评测）：≈70%
- 模型强化（YOLOv13 seg头+neck FiLM+小目标结构+一体化/软规则/几何一致性）：≈30% 待做

六、下一阶段两条主线（你确认选一条我就给补丁和脚本）
A. 切换 Stage1 到 YOLOv13 真正分割头（proto+coeff）+ neck-FiLM + P2/RepGFPN/DCNv3
- 最小侵入补丁：在 RepGFPN P3/P2 注入 FiLM；构建模型时开启 P2/RepGFPN/DCNv3；训练脚本 tools/train_yolov13_stage1.py（用 UnifiedSegDataset）；
- 输出标准 mAP50(M)/APS，与 Stage3 评测对齐。

B. 一体化 Mask2Morph 接回 YOLOv13（先用 GT ROI，再混预测 ROI）
- 在分割头后接 ROI-Align → 5 头（初始化用 best_student.pt），训练 CE + KL(teacher/student logits）；
- 后续叠加训练期软规则正则与几何一致性。

建议优先走 A（把 Stage1 指标切到标准 mAP），这样 Stage3 的检测/分割指标就与主流对齐。你确认选择 A 或 B，我就给对应的代码与修改点。