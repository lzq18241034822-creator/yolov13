好嘞！数据集和 YAML 都定版了，下一步我们先把“统一数据质检 + 统计报告”跑通，确保所有标签文件严格合规，再开始训练。这个环节很关键：一旦质检通过，后面的 dataloader、Baseline、µScale、小目标结构都会顺畅很多。

本步任务：统一数据集质检与统计报告
- 目标：
  - 严格校验每个 TXT 的格式、头部元数据、ID 合法性、分割点归一化、文件名-头部一致性；
  - 给出 species / cell_org / shape / flagella / chloroplast 的样本统计；
  - 提示“软规则冲突”（仅警告不阻塞），便于回修；
  - 检查是否存在未配对图片/标签。
- 你会得到：
  - 命令行日志（错误/警告/统计概览）
  - 报告文件：reports/validate_report.json 和 reports/summary.csv
- 通过标准：
  - 严重错误=0（err_count=0），警告可接受（如偶发变体/软规则提示）
  - TXT 头部与 YAML 一致（magnification、pixel_size_um、pixel_dimensions_px）
  - 坐标归一化、点数偶数、ID 范围全通过

代码：tools/validate_unified_dataset.py
- 单一模块，专做质检和统计。下一步我再给你“Stage1 统一格式 dataloader（多边形→自动bbox）”。

使用方式
- python tools/validate_unified_dataset.py --data_root "E:/yolov13/microalgae_unified_dataset" --cfg configs/yolov13_transformer_unified_v2_1.yaml
- 可选参数：
  - --split train val test 选择要检查的子集
  - --report_dir reports 指定报告输出目录

代码
请将以下脚本保存为 tools/validate_unified_dataset.py

```python
# -*- coding: utf-8 -*-
"""
统一数据集质检与统计报告（适配 µSHM-YOLO Unified-Final-2.1）
- 校验内容：
  1) 文件名模板与像素尺度位数
  2) TXT 头部5行与 YAML 一致性
  3) 每行：5个ID + 多边形点（偶数、归一化[0,1]）
  4) ID范围合法（含 cell_org=7/8/9/44，兼容10/11→多(>4)）
  5) 软规则冲突统计（警告不阻塞）
  6) 图像-标签配对完整性
- 输出：
  - 命令行摘要
  - JSON报告：reports/validate_report.json
  - CSV统计：reports/summary.csv
"""

import os
import re
import sys
import json
import math
import glob
import csv
import argparse
from collections import defaultdict, Counter

from ruamel.yaml import YAML

def load_yaml(path):
    y = YAML()
    with open(path, 'r', encoding='utf-8') as f:
        return y.load(f)

def fmt_pixel_size(val, digits=4, trim=False):
    s = f"{float(val):.{digits}f}"
    if trim and '.' in s:
        s = s.rstrip('0').rstrip('.')
    return s

def sanitize_name(name, sanitize_cfg):
    s = name
    repl = sanitize_cfg.get('replace', {})
    for k, v in repl.items():
        s = s.replace(k, v)
    for ch in sanitize_cfg.get('remove_chars', []):
        s = s.replace(ch, '')
    if sanitize_cfg.get('to_lowercase', False):
        s = s.lower()
    return s

def build_expected_label_name(template, microscope, image_stem, nf_conf, sanitize_cfg):
    px = fmt_pixel_size(microscope['pixel_size_um'],
                        nf_conf['pixel_size_um']['digits'],
                        nf_conf['pixel_size_um']['trim_trailing_zeros'])
    name = template.format(
        magnification=microscope.get('magnification', ''),
        pixel_size_um=px,
        pixel_dimensions_px=microscope.get('pixel_dimensions_px', ''),
        image_stem=image_stem
    )
    return sanitize_name(name, sanitize_cfg)

def parse_header(lines):
    """
    解析以 # 开头的头部元数据，格式: `# key: value`
    返回 dict 与 非头部起始行索引
    """
    header = {}
    start_idx = 0
    for i, line in enumerate(lines):
        s = line.strip()
        if not s:
            start_idx = i + 1
            continue
        if s.startswith('#'):
            s = s[1:].strip()
            if ':' in s:
                k, v = s.split(':', 1)
                header[k.strip()] = v.strip()
            start_idx = i + 1
        else:
            break
    return header, start_idx

def parse_label_line(line):
    """
    解析一行标注：
    5个ID + 多边形(x1 y1 ... xn yn), n>=6且为偶数
    返回：ids(list[int]), poly(list[float])
    """
    parts = line.strip().split()
    if len(parts) < 5 + 6:
        raise ValueError(f"line too short, need >= 11 numbers, got {len(parts)}")
    ids = list(map(int, parts[:5]))
    seg = list(map(float, parts[5:]))
    if len(seg) % 2 != 0:
        raise ValueError("segmentation points count must be even")
    return ids, seg

def poly_bounds(seg):
    xs = seg[0::2]
    ys = seg[1::2]
    return min(xs), min(ys), max(xs), max(ys)

def in_01(val, eps=1e-6):
    return -eps <= val <= 1 + eps

def check_ids(ids, cfg):
    """
    ids = [species, cell_org, shape, flagella, chloroplast]
    按 YAML groups 范围与兼容策略校验
    """
    species, cell_org, shape, flagella, chloroplast = ids
    groups = cfg['classes']['groups']
    ok = True
    msgs = []

    # species
    if species not in groups['species']['classes']:
        ok = False
        msgs.append(f"species={species} not in {groups['species']['classes']}")

    # cell_org: 允许 7/8/9/44，兼容旧10/11映射为44（这里允许出现10/11）
    allowed_cell_org = set([7, 8, 9, 44, 10, 11])
    if cell_org not in allowed_cell_org:
        ok = False
        msgs.append(f"cell_org={cell_org} invalid, allowed {sorted(list(allowed_cell_org))}")

    # shape
    if shape not in groups['shape']['classes']:
        ok = False
        msgs.append(f"shape={shape} not in {groups['shape']['classes']}")

    # flagella
    if flagella not in groups['flagella']['classes']:
        ok = False
        msgs.append(f"flagella={flagella} not in {groups['flagella']['classes']}")

    # chloroplast
    if chloroplast not in groups['chloroplast']['classes']:
        ok = False
        msgs.append(f"chloroplast={chloroplast} not in {groups['chloroplast']['classes']}")

    return ok, msgs

def soft_rule_check(ids, rules):
    """
    软规则校验（仅警告）：根据 species_morphology_rules
    返回 (pass_bool, warnings[list])
    """
    species, cell_org, shape, flagella, chloroplast = ids
    warns = []
    passed = True
    for rule in rules:
        if rule.get('species', None) != species:
            continue
        # required
        req = rule.get('required', {})
        for k, vals in req.items():
            val = {'cell_org': cell_org, 'shape': shape, 'flagella': flagella}.get(k, None)
            if val is not None and val not in vals:
                passed = False
                warns.append(f"required violation: {k}={val} not in {vals}")
        # forbidden
        forb = rule.get('forbidden', {})
        for k, vals in forb.items():
            val = {'cell_org': cell_org, 'shape': shape, 'flagella': flagella}.get(k, None)
            if val is not None and val in vals:
                passed = False
                warns.append(f"forbidden violation: {k}={val} in {vals}")
    return passed, warns

def validate_label_file(label_path, cfg, microscope, naming, id_maps, rules, summary):
    errors = []
    warnings = []
    file_ok = True

    # 读取文件
    with open(label_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    header, start_idx = parse_header(lines)
    # 头部检查
    required_keys = ["magnification", "pixel_size_um", "pixel_dimensions_px", "magnification_camera", "pixel_size_um_source"]
    for k in required_keys:
        if k not in header:
            file_ok = False
            errors.append(f"header missing key: {k}")

    # 与YAML一致性（严格等值）
    # pixel_size 需要按digits格式化比较
    nf = naming['number_format']
    expected_px = fmt_pixel_size(microscope['pixel_size_um'], nf['pixel_size_um']['digits'], nf['pixel_size_um']['trim_trailing_zeros'])
    if 'pixel_size_um' in header and header['pixel_size_um'] != str(expected_px):
        file_ok = False
        errors.append(f"header pixel_size_um mismatch, got {header.get('pixel_size_um')}, expect {expected_px}")
    if 'magnification' in header and header['magnification'] != microscope.get('magnification'):
        file_ok = False
        errors.append(f"header magnification mismatch, got {header.get('magnification')} expect {microscope.get('magnification')}")
    if 'pixel_dimensions_px' in header and header['pixel_dimensions_px'] != microscope.get('pixel_dimensions_px'):
        file_ok = False
        errors.append(f"header pixel_dimensions_px mismatch, got {header.get('pixel_dimensions_px')} expect {microscope.get('pixel_dimensions_px')}")
    if 'magnification_camera' in header and header['magnification_camera'] != microscope.get('magnification_camera'):
        warnings.append(f"header magnification_camera differs: {header.get('magnification_camera')} vs {microscope.get('magnification_camera')} (warn)")
    if 'pixel_size_um_source' in header and header['pixel_size_um_source'] != microscope.get('pixel_size_um_source'):
        warnings.append(f"header pixel_size_um_source differs: {header.get('pixel_size_um_source')} vs {microscope.get('pixel_size_um_source')} (warn)")

    # 行检查
    line_ok_count = 0
    for ln, line in enumerate(lines[start_idx:], start=start_idx+1):
        s = line.strip()
        if not s or s.startswith('#'):
            continue
        try:
            ids, seg = parse_label_line(s)
        except Exception as e:
            file_ok = False
            errors.append(f"line {ln}: parse error: {e}")
            continue

        # ID 合法性
        ok_ids, id_msgs = check_ids(ids, cfg)
        if not ok_ids:
            file_ok = False
            errors.append(f"line {ln}: id invalid: {', '.join(id_msgs)}")

        # 坐标范围与点数
        if len(seg) < 12 or len(seg) % 2 != 0:
            file_ok = False
            errors.append(f"line {ln}: need >=6 pts even-numbered, got {len(seg)//2} pts")
        # 归一化检查
        for k, v in enumerate(seg):
            if not in_01(v):
                file_ok = False
                errors.append(f"line {ln}: seg[{k}]={v:.6f} out of [0,1]")

        # bbox 合理性（由polygon计算）
        if len(seg) >= 4:
            x0, y0, x1, y1 = poly_bounds(seg)
            if not (x1 > x0 and y1 > y0):
                file_ok = False
                errors.append(f"line {ln}: degenerate bbox from polygon (w/h <= 0)")

        # 软规则校验（警告）
        rule_pass, warns = soft_rule_check(ids, rules)
        if not rule_pass and warns:
            warnings.append(f"line {ln}: soft-rule warning: " + " | ".join(warns))

        # 统计
        species, cell_org, shape, flagella, chloroplast = ids
        summary['species'][species] += 1
        # cell_org 将10/11并入44的统计桶
        co_bucket = cell_org if cell_org in (7, 8, 9, 44) else 44 if cell_org in (10, 11) else cell_org
        summary['cell_org'][co_bucket] += 1
        summary['shape'][shape] += 1
        summary['flagella'][flagella] += 1
        summary['chloroplast'][chloroplast] += 1

        if file_ok:
            line_ok_count += 1

    return file_ok and (line_ok_count > 0), errors, warnings

def collect_images_and_labels(data_root, split, naming, microscope):
    img_dir = os.path.join(data_root, 'images', split)
    lbl_dir = os.path.join(data_root, 'labels', split)
    nf = naming['number_format']
    sanitize_cfg = naming.get('sanitize', {})

    images = []
    for ext in ('*.jpg','*.jpeg','*.png','*.bmp','*.tif','*.tiff'):
        images.extend(glob.glob(os.path.join(img_dir, ext)))
    images = sorted(images)

    labels = sorted(glob.glob(os.path.join(lbl_dir, '*.txt')))

    # 建立映射：image_stem -> expected_label_path
    expected_map = {}
    for img_path in images:
        stem = os.path.splitext(os.path.basename(img_path))[0]
        expected_name = build_expected_label_name(naming['label_filename_template'], microscope, stem, nf, sanitize_cfg)
        expected_map[img_path] = os.path.join(lbl_dir, expected_name)

    return images, labels, expected_map

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_root", type=str, required=True, help="数据集根目录（包含 images/ 与 labels/）")
    parser.add_argument("--cfg", type=str, required=True, help="YAML 配置文件路径")
    parser.add_argument("--splits", nargs="+", default=["train","val","test"], help="要校验的子集")
    parser.add_argument("--report_dir", type=str, default="reports", help="报告输出目录")
    args = parser.parse_args()

    cfg = load_yaml(args.cfg)
    naming = cfg['dataset']['naming']
    microscope = cfg['microscope'] if 'microscope' in cfg else cfg['dataset']['microscope']
    rules = cfg['stage3_integration']['rule_engine']['species_morphology_rules'] if 'stage3_integration' in cfg and cfg['stage3_integration'].get('rule_engine',{}).get('enabled',False) else []

    os.makedirs(args.report_dir, exist_ok=True)

    total_files = 0
    total_errors = 0
    total_warnings = 0
    missing_labels = []
    orphan_labels = []
    all_summary = {
        'species': Counter(),
        'cell_org': Counter(),
        'shape': Counter(),
        'flagella': Counter(),
        'chloroplast': Counter(),
    }
    file_reports = {}

    for sp in args.splits:
        print(f"\n=== Checking split: {sp} ===")
        images, labels, expected_map = collect_images_and_labels(args.data_root, sp, naming, microscope)
        label_set = set(labels)

        # 检查每张图的标签是否存在
        for img_path, exp_lbl in expected_map.items():
            total_files += 1
            if not os.path.exists(exp_lbl):
                missing_labels.append({'split': sp, 'image': img_path, 'expected_label': exp_lbl})
                total_errors += 1
                continue

            # 校验标签内容
            summary = {k: Counter() for k in ['species','cell_org','shape','flagella','chloroplast']}
            ok, errs, warns = validate_label_file(exp_lbl, cfg, microscope, naming, cfg['classes']['label_spaces'], rules, summary)
            total_errors += len(errs)
            total_warnings += len(warns)
            file_reports[exp_lbl] = {
                'ok': ok and (len(errs)==0),
                'errors': errs,
                'warnings': warns,
                'summary': {k: dict(v) for k, v in summary.items()}
            }
            # 汇总统计
            for k in all_summary.keys():
                all_summary[k].update(summary[k])

        # 检查孤儿标签（没有对应图片）
        lbl_dir = os.path.join(args.data_root, 'labels', sp)
        for lbl in glob.glob(os.path.join(lbl_dir, '*.txt')):
            # 解析 image_stem
            base = os.path.basename(lbl)
            # 移除头前缀 "{magnification}-{pixel_size_um}um_"
            # 简单匹配：第一个 '_' 之后的部分去掉扩展名即为 image_stem
            if '_' in base:
                image_stem = os.path.splitext(base.split('_', 1)[1])[0]
                img_candidates = []
                for ext in ('.jpg','.jpeg','.png','.bmp','.tif','.tiff'):
                    p = os.path.join(args.data_root, 'images', sp, image_stem + ext)
                    if os.path.exists(p):
                        img_candidates.append(p)
                if not img_candidates:
                    orphan_labels.append({'split': sp, 'label': lbl, 'hint_image_stem': image_stem})

    # 输出报告
    report = {
        'total_files_checked': total_files,
        'total_errors': total_errors,
        'total_warnings': total_warnings,
        'missing_labels': missing_labels,
        'orphan_labels': orphan_labels,
        'file_reports': file_reports,
        'summary_totals': {k: dict(v) for k, v in all_summary.items()}
    }
    json_path = os.path.join(args.report_dir, 'validate_report.json')
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    # CSV概要
    csv_path = os.path.join(args.report_dir, 'summary.csv')
    with open(csv_path, 'w', newline='', encoding='utf-8') as f:
        w = csv.writer(f)
        w.writerow(['metric','id','count'])
        for k, counter in all_summary.items():
            for cid, cnt in counter.items():
                w.writerow([k, cid, cnt])

    # 控制台摘要
    print("\n==== Validation Summary ====")
    print(f"Files checked: {total_files}")
    print(f"Errors: {total_errors}")
    print(f"Warnings: {total_warnings}")
    print(f"Report JSON: {json_path}")
    print(f"Summary CSV: {csv_path}")

    if missing_labels:
        print(f"\n[Missing labels] {len(missing_labels)} cases:")
        for e in missing_labels[:10]:
            print(f"  {e['image']} -> expected {e['expected_label']}")
        if len(missing_labels) > 10:
            print("  ...")

    if orphan_labels:
        print(f"\n[Orphan labels] {len(orphan_labels)} cases:")
        for e in orphan_labels[:10]:
            print(f"  {e['label']} (stem={e['hint_image_stem']})")
        if len(orphan_labels) > 10:
            print("  ...")

    # 返回码：有严重错误时非零
    sys.exit(0 if total_errors == 0 else 1)

if __name__ == "__main__":
    main()
```

执行步骤
1) 先跑质检：
- python tools/validate_unified_dataset.py --data_root "E:/yolov13/microalgae_unified_dataset" --cfg configs/yolov13_transformer_unified_v2_1.yaml

2) 查看输出：
- 控制台错误/警告统计
- reports/validate_report.json（每个文件的错误/警告/行号细节）
- reports/summary.csv（各维度 ID 的样本分布）

3) 如有错误：
- 根据报告修正具体 TXT 或图像文件名
- 常见问题：
  - 文件名前缀与头部像素尺度不一致
  - 分割点不是偶数/有坐标超出[0,1]
  - species/cell_org/shape/flagella/chloroplast ID 越界
  - 边界退化（polygon点重复导致bbox w/h=0）

通过后，下一步任务（预告）
- 我将给你“Stage1 统一格式 dataloader（unified_format_parser）”的代码：
  - 支持你的新格式“5ID + polygon（无bbox字段）”
  - 自动由 polygon 生成归一化 bbox 传给 YOLOv8-Seg
  - 训练时将所有实例类别强制为 0（单类分割），并按 skip_species_ids 跳过伪影类
- 完成 dataloader 后，你就能直接启动 Baseline 训练（100–150 epoch 先跑通），同时输出 ROI crops 以备后续 Stage2 蒸馏使用。

你先把质检脚本跑一遍，把报告发我（或关键摘要），我再按你的情况给出下一个模块的代码与训练指令。