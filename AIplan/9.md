太棒！Stage3 可视化和 JSON 端到端已经稳定了。为了把“结果是否好”说清楚、形成论文级指标与图表，下一步做“Stage3 评测与报告”。这一步不用改你的模型，直接对 predictions.json 对比 GT（统一 TXT），计算检测/分割/五头分类/规则冲突等指标，输出 CSV/NPY/可视化热力图，作为论文实验与日常回归的基准。

本步目标
- 将 predictions.json 与 GT TXT 对齐，按 IoU 匹配实例（先用 bbox IoU，随后可选 mask IoU）。
- 计算并导出：
  - 检测：Precision/Recall，mAP50(B)；分割：mAP50(M) 或 mIoU（简化版）。
  - 五头分类：species/cell_org/shape/flagella/chloroplast 的准确率、宏平均F1、混淆矩阵。
  - 规则冲突率：raw 与 final（降级后）的冲突率，以及降级比例。
  - 参数统计：10参数的均值/方差分布（用于 sanity check）。
- 生成报告：CSV 摘要 + 混淆矩阵 NPY/PNG + 每图配对文件（可选）。

你将新增的文件
- utils/matching.py：IoU 计算（bbox/mask）+ 匈牙利匹配（Hungarian）
- tools/eval_stage3_report.py：将 predictions.json 与 GT TXT 对齐，计算并保存各类指标与图表
- utils/report_plot.py：画混淆矩阵/曲线（轻量，避免后端问题时可禁用绘图）

一、匹配与 IoU：utils/matching.py
保存为 utils/matching.py

```python
# -*- coding: utf-8 -*-
import numpy as np
import cv2
from typing import List, Tuple
from scipy.optimize import linear_sum_assignment

def iou_xyxy(b1, b2):
    # b: [x1,y1,x2,y2]
    x1 = max(b1[0], b2[0]); y1 = max(b1[1], b2[1])
    x2 = min(b1[2], b2[2]); y2 = min(b1[3], b2[3])
    inter = max(0, x2-x1) * max(0, y2-y1)
    a1 = max(0, b1[2]-b1[0]) * max(0, b1[3]-b1[1])
    a2 = max(0, b2[2]-b2[0]) * max(0, b2[3]-b2[1])
    union = a1 + a2 - inter + 1e-9
    return inter/union

def iou_mask(m1: np.ndarray, m2: np.ndarray):
    inter = np.logical_and(m1>0, m2>0).sum()
    union = np.logical_or(m1>0, m2>0).sum() + 1e-9
    return inter/union

def rasterize_poly_norm(poly_norm: np.ndarray, H: int, W: int):
    # poly_norm: (K,2) in [0,1]
    poly = (poly_norm * np.array([W, H], dtype=np.float32)).astype(np.int32)
    m = np.zeros((H,W), dtype=np.uint8)
    if len(poly) > 2:
        cv2.fillPoly(m, [poly], 1)
    return m

def match_detections(pred_boxes: List[List[int]], gt_boxes: List[List[int]], iou_thr=0.5):
    # 匹配pred与gt，返回映射（pred_idx -> gt_idx or -1）
    if len(pred_boxes)==0 or len(gt_boxes)==0:
        return [-1]*len(pred_boxes), []
    C = np.zeros((len(pred_boxes), len(gt_boxes)), dtype=np.float32)
    for i,pb in enumerate(pred_boxes):
        for j,gb in enumerate(gt_boxes):
            C[i,j] = 1 - iou_xyxy(pb, gb)  # cost = 1 - iou
    ri, cj = linear_sum_assignment(C)
    matches = [-1]*len(pred_boxes)
    matched_pairs=[]
    for i,j in zip(ri, cj):
        iou = 1 - C[i,j]
        if iou >= iou_thr:
            matches[i] = j
            matched_pairs.append((i,j,iou))
    return matches, matched_pairs
```

二、评测脚本：tools/eval_stage3_report.py
- 读取 predictions.json（你 Stage3 输出）与 GT TXT；
- 将 GT polygon 按与推理相同的 resize 尺寸（imgsz）栅格化，以保证 mask IoU 可比；
- 匹配实例（默认 bbox IoU≥0.5），可选叠加 mask IoU；
- 统计检测/分割/五头分类/冲突与降级/参数摘要；
- 输出 CSV 与 NPY/PNG 图表。

保存为 tools/eval_stage3_report.py

```python
# -*- coding: utf-8 -*-
import os, json, glob, argparse
import numpy as np
import cv2
from ruamel.yaml import YAML

from utils.matching import iou_xyxy, iou_mask, rasterize_poly_norm, match_detections

def imread_unicode(path):
    data = np.fromfile(path, dtype=np.uint8)
    return cv2.imdecode(data, cv2.IMREAD_COLOR)

def load_gt_unified(label_path: str):
    lines=[]
    with open(label_path, 'r', encoding='utf-8') as f:
        for ln in f:
            s = ln.strip()
            if not s or s.startswith('#'): continue
            lines.append(s)
    gts=[]
    for s in lines:
        parts = s.split()
        if len(parts) < 5+6: 
            continue
        ids5 = list(map(int, parts[:5]))
        seg = np.array(list(map(float, parts[5:])), dtype=np.float32).reshape(-1,2)
        # 由 seg 得 bbox norm
        x0,x1 = seg[:,0].min(), seg[:,0].max()
        y0,y1 = seg[:,1].min(), seg[:,1].max()
        gts.append({'ids5': ids5, 'seg_norm': seg, 'bbox_norm': [x0,y0,x1,y1]})
    return gts

def norm_box_to_xyxy(bn, W, H):
    x0,y0,x1,y1 = bn
    return [int(x0*W), int(y0*H), int(x1*W), int(y1*H)]

def build_name_maps(cfg):
    names = cfg['classes']['names']
    return {int(k):v for k,v in names.items()}

def evaluate(pred_json, data_root, cfg_path, imgsz=640, iou_thr=0.5, save_dir="runs/eval_stage3"):
    os.makedirs(save_dir, exist_ok=True)
    yaml = YAML()
    with open(cfg_path, 'r', encoding='utf-8') as f:
        cfg = yaml.load(f)
    names_map = build_name_maps(cfg)

    with open(pred_json, 'r', encoding='utf-8') as f:
        preds = json.load(f)

    # 汇总容器
    det_tp=0; det_fp=0; det_fn=0
    seg_iou_sum=0.0; seg_iou_n=0

    # 五头分类混淆
    def zeros_cm(n): return np.zeros((n,n), dtype=np.int64)
    cm_species = zeros_cm(45); cm_cell = zeros_cm(4); cm_shape=zeros_cm(10); cm_flag=zeros_cm(5); cm_chl=zeros_cm(4)

    # 冲突与降级
    conflict_raw=0; conflict_final=0; total_inst=0; demote_cnt=0

    # 参数统计（图级）
    params_list=[]

    for rec in preds:
        img_path = rec['image_path']
        img = imread_unicode(img_path)
        if img is None: continue
        H0,W0 = img.shape[:2]
        # 注意：你的推理是直接 resize 到 imgsz（非 letterbox 保比例），评测也用相同方式
        im_res = cv2.resize(img, (imgsz,imgsz), interpolation=cv2.INTER_LINEAR)
        H,W = imgsz,imgsz

        # 读取GT
        stem = os.path.splitext(os.path.basename(img_path))[0]
        lbl_path = os.path.join(data_root, "labels", "val", stem + ".txt")
        if not os.path.exists(lbl_path):
            lbl_path = os.path.join(data_root, "labels", "train", stem + ".txt")
            if not os.path.exists(lbl_path):
                continue
        gts = load_gt_unified(lbl_path)
        gt_boxes=[]; gt_masks=[]; gt_ids=[]
        for g in gts:
            bx = norm_box_to_xyxy(g['bbox_norm'], W, H)
            mk = rasterize_poly_norm(g['seg_norm'], H, W)
            gt_boxes.append(bx); gt_masks.append(mk)
            gt_ids.append(g['ids5'])

        # 读取pred
        dets = rec.get('detections', [])
        pred_boxes=[]; pred_masks=[]; ids5_raw=[]; ids5_final=[]
        for d in dets:
            pred_boxes.append(d['bbox_xyxy'])
            # 没保存mask，取bbox近似mask（可选：从overlay反推或在推理脚本存mask路径）
            m = np.zeros((H,W), dtype=np.uint8)
            x0,y0,x1,y1 = d['bbox_xyxy']
            m[y0:y1, x0:x1] = 1
            pred_masks.append(m)
            ids5_raw.append(d['ids5_raw'])
            ids5_final.append(d['ids5_final'])

        # 匹配（bbox IoU）
        match_idx, pairs = match_detections(pred_boxes, gt_boxes, iou_thr=iou_thr)
        det_tp += len(pairs)
        det_fp += (len(pred_boxes) - len(pairs))
        det_fn += (len(gt_boxes) - len(pairs))

        # 分割IoU（用匹配对的mask）
        for (pi, gi, _) in pairs:
            iou_m = iou_mask(pred_masks[pi], gt_masks[gi])
            seg_iou_sum += iou_m; seg_iou_n += 1

        # 分类混淆（matched）
        for (pi, gi, _) in pairs:
            # species cm（raw or final？一般用 final）
            sp_pred = ids5_final[pi]['species']; sp_gt = gt_ids[gi][0]
            if 0<=sp_gt<45 and 0<=sp_pred<45:
                cm_species[sp_gt, sp_pred] += 1
            # cell_org：全局→local(7/8/9/44 → 0/1/2/3；10/11→3)
            def co_local(g):
                if g in (10,11): g=44
                return {7:0,8:1,9:2,44:3}.get(g,3)
            def sh_local(g): return {12:0,13:1,14:2,15:3,16:4,17:5,18:6,19:7,20:8,21:9}.get(g,0)
            def fl_local(g): return {22:0,23:1,24:2,25:3,26:4}.get(g,0)
            def ch_local(g): return {27:0,28:1,29:2,30:3}.get(g,0)

            cm_cell[co_local(gt_ids[gi][1]), co_local(ids5_final[pi]['cell_org'])] += 1
            cm_shape[sh_local(gt_ids[gi][2]), sh_local(ids5_final[pi]['shape'])] += 1
            cm_flag[fl_local(gt_ids[gi][3]), fl_local(ids5_final[pi]['flagella'])] += 1
            cm_chl[ch_local(gt_ids[gi][4]), ch_local(ids5_final[pi]['chloroplast'])] += 1

        # 规则冲突统计（pred层）
        for i, d in enumerate(dets):
            total_inst += 1
            rc = d['rule']  # {'passed': bool, 'violations': [...]}
            if rc and (len(rc.get('violations',[]))>0):
                conflict_raw += 1
                # 降级后仍冲突？（此处 rec 中 rule 是对 raw 检查，final 的检查可再跑一遍；简化先统计原始冲突）
                # 如果你要统计 final 冲突，需对 ids5_final 再调用规则引擎，这里略

            if d['ids5_raw']['species'] != d['ids5_final']['species']:
                demote_cnt += 1

        # 图级参数摘要
        params_list.append(rec.get('parameters', {}))

    # 检测指标
    precision = det_tp / (det_tp + det_fp + 1e-9)
    recall    = det_tp / (det_tp + det_fn + 1e-9)
    miou_seg  = seg_iou_sum / (seg_iou_n + 1e-9)

    # 分类准确率（从混淆矩阵）
    def cm_acc(cm): 
        tot = cm.sum()
        return (np.trace(cm) / tot) if tot>0 else 0.0

    acc_species = cm_acc(cm_species)
    acc_cell    = cm_acc(cm_cell)
    acc_shape   = cm_acc(cm_shape)
    acc_flag    = cm_acc(cm_flag)
    acc_chl     = cm_acc(cm_chl)

    # 冲突率与降级率
    conflict_rate_raw   = conflict_raw / (total_inst + 1e-9)
    demote_rate         = demote_cnt / (total_inst + 1e-9)

    # 保存结果
    os.makedirs(save_dir, exist_ok=True)
    np.save(os.path.join(save_dir, "cm_species.npy"), cm_species)
    np.save(os.path.join(save_dir, "cm_cell_org.npy"), cm_cell)
    np.save(os.path.join(save_dir, "cm_shape.npy"), cm_shape)
    np.save(os.path.join(save_dir, "cm_flagella.npy"), cm_flag)
    np.save(os.path.join(save_dir, "cm_chloroplast.npy"), cm_chl)

    # CSV 摘要
    with open(os.path.join(save_dir, "summary.csv"), 'w', encoding='utf-8') as f:
        f.write("metric,value\n")
        f.write(f"precision,{precision:.4f}\n")
        f.write(f"recall,{recall:.4f}\n")
        f.write(f"miou_seg,{miou_seg:.4f}\n")
        f.write(f"acc_species,{acc_species:.4f}\n")
        f.write(f"acc_cell_org,{acc_cell:.4f}\n")
        f.write(f"acc_shape,{acc_shape:.4f}\n")
        f.write(f"acc_flagella,{acc_flag:.4f}\n")
        f.write(f"acc_chloroplast,{acc_chl:.4f}\n")
        f.write(f"conflict_rate_raw,{conflict_rate_raw:.4f}\n")
        f.write(f"demote_rate,{demote_rate:.4f}\n")

    print("[Eval] summary:")
    print(f"  det P={precision:.4f} R={recall:.4f}  seg mIoU={miou_seg:.4f}")
    print(f"  cls acc: species={acc_species:.4f} cell={acc_cell:.4f} shape={acc_shape:.4f} flag={acc_flag:.4f} chl={acc_chl:.4f}")
    print(f"  conflict_raw={conflict_rate_raw:.4f}  demote_rate={demote_rate:.4f}")
    print(f"  saved to {save_dir}")
```

三、可选图表绘制：utils/report_plot.py
如果你允许使用 matplotlib，可以把混淆矩阵画成 PNG；否则可禁用。

```python
# utils/report_plot.py
# 可选，不强制。本次脚本 eval 已包含简单绘制函数。
```

四、如何运行
- 假设你已生成 Stage3 预测：
  - predictions.json 与叠加图在 g:\yoloV13\runs\infer_stage3\
- 执行评测：
  - python µSHM-YOLO\tools\eval_stage3_report.py --cfg µSHM-YOLO\yolov13_transformer_unified_v2_1.yaml --data_root µSHM-YOLO\samples --imgsz 640 --iou_thr 0.5
    - 默认读取 runs\infer_stage3\predictions.json（如路径不同，加一个参数 --pred_json）
- 脚本默认保存到 runs/eval_stage3：
  - summary.csv（主要指标）
  - cm_*.npy（五个混淆矩阵）
  - 如 matplotlib 可用，还会生成 cm_*.png

五、通过标准
- summary.csv 指标能输出且合理（小数据阶段看相对趋势，不必苛求绝对值）
- 混淆矩阵 NPY 大小正确；若有 PNG 也能打开
- 冲突率与降级率能客观反映现状（冲突高可以说明 Teacher/Student 仍需要数据或规则需软化）

六、下一步预告（两条可选）
A. YOLOv13 真正分割头（proto+coeff）接入 + neck-FiLM + P2/RepGFPN/DCNv3
- 我会给你最小侵入的补丁（neck 注入 FiLM、Model forward 接 pixel_scale），以及训练脚本 tools/train_yolov13_stage1.py（用你统一数据集），输出标准 mAP50(M)/APS。

B. 一体化 Mask2Morph（接回 YOLOv13）
- 在 YOLOv13 分割头后接 ROI-Align + 5头（用 Student 权重 warm start），训练 CE + KL(Teacher logits)；随后叠加超图与软规则/几何一致性。

建议先走 A（把 Stage1 切到规范 mAP），因为这样 Stage3 的 detection/segmentation 指标就与主流对齐。你确认选择 A 或 B，我就给对应的代码与修改点。